 
@Book{harvey1990,
  author    = {Harvey, Andrew C.},
  publisher = {Cambridge University Press},
  title     = {Forecasting, structural time series models and the {Kalman} filter},
  year      = {1990},
  address   = {Cambridge},
  isbn      = {9780521321969},
  abstract  = {In this book, Andrew Harvey sets out to provide a unified and comprehensive theory of structural time series models. Unlike the traditional ARIMA models, structural time series models consist explicitly of unobserved components, such as trends and seasonals, which have a direct interpretation. As a result the model selection methodology associated with structural models is much closer to econometric methodology. The link with econometrics is made even closer by the natural way in which the models can be extended to include explanatory variables and to cope with multivariate time series. From the technical point of view, state space models and the Kalman filter play a key role in the statistical treatment of structural time series models. The book includes a detailed treatment of the Kalman filter. This technique was originally developed in control engineering, but is becoming increasingly important in fields such as economics and operations research. This book is concerned primarily with modelling economic and social time series, and with addressing the special problems which the treatment of such series poses. The properties of the models and the methodological techniques used to select them are illustrated with various applications. These range from the modellling of trends and cycles in US macroeconomic time series to to an evaluation of the effects of seat belt legislation in the UK.},
  doi       = {10.1017/CBO9781107049994},
  file      = {:harvey1990 - Forecasting, Structural Time Series Models and the Kalman Filter.pdf:PDF},
  groups    = {SSM},
  priority  = {prio2},
  url       = {https://www.cambridge.org/core/books/forecasting-structural-time-series-models-and-the-kalman-filter/CE5E112570A56960601760E786A5E631},
  urldate   = {2022-10-14},
}

@Article{wong1985,
  author  = {Wong, George Y. and Mason, William M.},
  journal = {Journal of the American Statistical Association},
  title   = {The hierarchical logistic regression model for multilevel analysis},
  year    = {1985},
  month   = {09},
  number  = {391},
  pages   = {513--524},
  volume  = {80},
  date    = {1985-09},
  doi     = {10.1080/01621459.1985.10478148},
  groups  = {HM/MEM},
  langid  = {en},
  url     = {http://dx.doi.org/10.1080/01621459.1985.10478148},
}

@Article{sullivan1999,
  author  = {Sullivan, Lisa M. and Dukes, Kimberly A. and Losina, Elena},
  journal = {Statistics in Medicine},
  title   = {An introduction to hierarchical linear modelling},
  year    = {1999},
  month   = {04},
  number  = {7},
  pages   = {855--888},
  volume  = {18},
  date    = {1999-04-15},
  doi     = {10.1002/(sici)1097-0258(19990415)18:7<855::aid-sim117>3.0.co;2-7},
  groups  = {HM/MEM},
  langid  = {en},
  url     = {http://dx.doi.org/10.1002/(SICI)1097-0258(19990415)18:7<855::AID-SIM117>3.0.CO;2-7},
}

@Book{raudenbush2002,
  author    = {Raudenbush, Stephen W. and Bryk, Anthony S.},
  publisher = {SAGE},
  title     = {Hierarchical linear models: Applications and data analysis methods},
  year      = {2002},
  edition   = {2nd},
  isbn      = {9780761919049},
  groups    = {HM/MEM},
  url       = {https://us.sagepub.com/en-us/nam/hierarchical-linear-models/book9230#reviews},
}

@Book{fahrmeir2013,
  author    = {Fahrmeir, Ludwig and Kneib, Thomas and Lang, Stefan and Marx, Brian},
  publisher = {Springer},
  title     = {Regression: Models, methods, and applications},
  year      = {2013},
  date      = {2013},
  doi       = {10.1007/978-3-642-34333-9},
  groups    = {HM/MEM, Regression},
  url       = {http://dx.doi.org/10.1007/978-3-642-34333-9},
}

@Article{gelman2006,
  author = {Gelman, Andrew and Hill, Jennifer},
  title  = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
  year   = {2006},
  date   = {2006},
  doi    = {10.1017/cbo9780511790942},
  groups = {HM/MEM},
  url    = {http://dx.doi.org/10.1017/CBO9780511790942},
}

@Article{bates2015,
  author = {Bates, Douglas and {M{ä}chler}, Martin and Bolker, Ben and Walker, Steve},
  title  = {Fitting Linear Mixed-Effects Models Using {\textbraceleft}lme4{\textbraceright}},
  year   = {2015},
  volume = {67},
  date   = {2015},
  doi    = {10.18637/jss.v067.i01},
  groups = {HM/MEM},
}

@Book{galecki2013,
  author    = {{Ga{\l}ecki}, Andrzej and Burzykowski, Tomasz},
  publisher = {Springer New York},
  title     = {Linear Mixed-Effects Models Using R},
  year      = {2013},
  date      = {2013},
  doi       = {10.1007/978-1-4614-3900-4},
  groups    = {HM/MEM},
  url       = {http://dx.doi.org/10.1007/978-1-4614-3900-4},
}

@Article{wakker1996,
  author  = {Wakker, Peter P. and Deneffe, Daniel},
  journal = {Management Science},
  title   = {Eliciting von Neumann-Morgenstern Utilities When Probabilities Are Distorted or Unknown},
  year    = {1996},
  month   = {08},
  number  = {8},
  pages   = {1131--1150},
  volume  = {42},
  date    = {1996-08},
  doi     = {10.1287/mnsc.42.8.1131},
  groups  = {Prospect theory},
  langid  = {en},
  url     = {http://dx.doi.org/10.1287/mnsc.42.8.1131},
}

@Article{wakker2008,
  author     = {Wakker, Peter P.},
  journal    = {Health Economics},
  title      = {Explaining the characteristics of the power ({CRRA}) utility family},
  year       = {2008},
  month      = {12},
  number     = {12},
  pages      = {1329--1344},
  volume     = {17},
  date       = {2008-12},
  doi        = {10.1002/hec.1331},
  file       = {:wakker2008 - Explaining the Characteristics of the Power (CRRA) Utility Family.pdf:PDF},
  groups     = {Prospect theory},
  langid     = {en},
  readstatus = {read},
  url        = {http://dx.doi.org/10.1002/hec.1331},
}

@Book{wakker2010,
  author     = {Wakker, Peter P.},
  publisher  = {Cambridge University Press},
  title      = {Prospect theory: For risk and ambiguity},
  year       = {2010},
  month      = {07},
  doi        = {10.1017/cbo9780511779329},
  file       = {:wakker2010 - Prospect Theory_ for Risk and Ambiguity.pdf:PDF},
  groups     = {Prospect theory},
  place      = {Cambridge},
  priority   = {prio1},
  readstatus = {skimmed},
  url        = {http://dx.doi.org/10.1017/CBO9780511779329},
}

@Article{distefano2012,
  author     = {Distefano, Salvatore and Longo, Francesco and Trivedi, Kishor S.},
  journal    = {Computers \& Mathematics with Applications},
  title      = {Investigating dynamic reliability and availability through state–space models},
  year       = {2012},
  number     = {12},
  pages      = {3701--3716},
  volume     = {64},
  doi        = {10.1016/j.camwa.2012.02.038},
  file       = {:distefano2012 - Investigating Dynamic Reliability and Availability through State–space Models.pdf:PDF},
  groups     = {SSM, Longitudinal data, Reliability},
  priority   = {prio1},
  publisher  = {Elsevier},
  readstatus = {skimmed},
}

 
@Article{joergensen1996,
  author     = {Jørgensen, Bent and Lundbye-Christensen, Søren and Song, Peter Xue-Kun and Sun, Li},
  journal    = {Canadian Journal of Statistics},
  title      = {State-space models for multivariate longitudinal data of mixed types},
  year       = {1996},
  number     = {3},
  pages      = {385--402},
  volume     = {24},
  doi        = {10.2307/3315747},
  file       = {:joergensen1996 - State Space Models for Multivariate Longitudinal Data of Mixed Types.pdf:PDF},
  groups     = {SSM},
  publisher  = {Wiley Online Library},
  ranking    = {rank4},
  readstatus = {read},
}

@Book{shoukri2010,
  author     = {Shoukri, Mohamed M.},
  publisher  = {CRC Press},
  title      = {Measures of interobserver agreement and reliability},
  year       = {2010},
  edition    = {2nd},
  isbn       = {9780429148590},
  month      = dec,
  doi        = {10.1201/b10433},
  file       = {:shoukri2010 - Measures of Interobserver Agreement and Reliability.pdf:PDF},
  groups     = {ICC, Reliability, Overview},
  priority   = {prio1},
  readstatus = {skimmed},
}

@Book{walls2006,
  editor     = {Walls, Theodore A. and Schafer, Joseph L.},
  publisher  = {Oxford University Press},
  title      = {Models for intensive longitudinal data},
  year       = {2006},
  isbn       = {9780195173444},
  month      = feb,
  abstract   = {A new class of longitudinal data has emerged with the use of technological devices for scientific data collection. This class of data is called intensive longitudinal data (ILD). This book features applied statistical modelling strategies developed by leading statisticians and methodologists working in conjunction with behavioural scientists.},
  doi        = {10.1093/acprof:oso/9780195173444.001.0001},
  file       = {:walls2006 - Models for Intensive Longitudinal Data.pdf:PDF},
  groups     = {ILD, SSM, MVAR, RILD},
  priority   = {prio2},
  readstatus = {skimmed},
  url        = {https://doi.org/10.1093/acprof:oso/9780195173444.001.0001},
}

 
@Book{choudhary2017,
  author     = {Choudhary, Pankaj K. and Nagaraja, Haikady N.},
  publisher  = {John Wiley \& Sons},
  title      = {Measuring {Agreement}: {Models}, {Methods}, and {Applications}},
  year       = {2017},
  isbn       = {9781118078587},
  month      = nov,
  note       = {Google-Books-ID: EJgtCwAAQBAJ},
  abstract   = {Presents statistical methodologies for analyzing common types of data from method comparison experiments and illustrates their applications through detailed case studies Measuring Agreement: Models, Methods, and Applications features statistical evaluation of agreement between two or more methods of measurement of a variable with a primary focus on continuous data. The authors view the analysis of method comparison data as a two-step procedure where an adequate model for the data is found, and then inferential techniques are applied for appropriate functions of parameters of the model. The presentation is accessible to a wide audience and provides the necessary technical details and references. In addition, the authors present chapter-length explorations of data from paired measurements designs, repeated measurements designs, and multiple methods; data with covariates; and heteroscedastic, longitudinal, and categorical data. The book also: • Strikes a balance between theory and applications • Presents parametric as well as nonparametric methodologies • Provides a concise introduction to Cohen’s kappa coefficient and other measures of agreement for binary and categorical data • Discusses sample size determination for trials on measuring agreement • Contains real-world case studies and exercises throughout • Provides a supplemental website containing the related datasets and R code Measuring Agreement: Models, Methods, and Applications is a resource for statisticians and biostatisticians engaged in data analysis, consultancy, and methodological research. It is a reference for clinical chemists, ecologists, and biomedical and other scientists who deal with development and validation of measurement methods. This book can also serve as a graduate-level text for students in statistics and biostatistics.},
  doi        = {10.1002/9781118553282},
  file       = {:choudhary2017 - Measuring Agreement_ Models, Methods, and Applications.pdf:PDF},
  groups     = {Overview, Reliability},
  keywords   = {Medical / Biostatistics, Education / Evaluation \& Assessment, Medical / Epidemiology, Mathematics / Probability \& Statistics / Stochastic Processes},
  language   = {en},
  priority   = {prio2},
  shorttitle = {Measuring {Agreement}},
}

 
@Article{hamaker2015,
  author     = {Hamaker, E. L. and Ceulemans, E. and Grasman, R. P. P. P. and Tuerlinckx, F.},
  journal    = {Emotion Review},
  title      = {Modeling affect dynamics: State of the art and future challenges},
  year       = {2015},
  issn       = {1754-0739},
  month      = oct,
  number     = {4},
  pages      = {316--322},
  volume     = {7},
  abstract   = {The current article aims to provide an up-to-date synopsis of available techniques to study affect dynamics using intensive longitudinal data (ILD). We do so by introducing the following eight dichotomies that help elucidate what kind of data one has, what process aspects are of interest, and what research questions are being considered: (1) single- versus multiple-person data; (2) univariate versus multivariate models; (3) stationary versus nonstationary models; (4) linear versus nonlinear models; (5) discrete time versus continuous time models; (6) discrete versus continuous variables; (7) time versus frequency domain; and (8) modeling the process versus computing descriptives. In addition, we discuss what we believe to be the most urging future challenges regarding the modeling of affect dynamics.},
  doi        = {10.1177/1754073915590619},
  file       = {:hamaker2015 - Modeling Affect Dynamics_ State of the Art and Future Challenges.pdf:PDF},
  groups     = {ILD, RILD, Affect},
  keywords   = {affective dynamics, intensive longitudinal data, within-person},
  language   = {en},
  publisher  = {SAGE Publications},
  ranking    = {rank3},
  readstatus = {read},
  shorttitle = {Modeling {Affect} {Dynamics}},
  url        = {https://doi.org/10.1177/1754073915590619},
  urldate    = {2022-08-28},
}

 
@Article{czado2008,
  author     = {Czado, Claudia and Song, Peter X.-K.},
  journal    = {Statistical Papers},
  title      = {State space mixed models for longitudinal observations with binary and binomial responses},
  year       = {2008},
  issn       = {1613-9798},
  month      = oct,
  number     = {4},
  pages      = {691--714},
  volume     = {49},
  abstract   = {We propose a new class of state space models for longitudinal discrete response data where the observation equation is specified in an additive form involving both deterministic and random linear predictors. These models allow us to explicitly address the effects of trend, seasonal or other time-varying covariates while preserving the power of state space models in modeling serial dependence in the data. We develop a Markov chain Monte Carlo algorithm to carry out statistical inference for models with binary and binomial responses, in which we invoke de Jong and Shephard’s (Biometrika 82(2):339–350, 1995) simulation smoother to establish an efficient sampling procedure for the state variables. To quantify and control the sensitivity of posteriors on the priors of variance parameters, we add a signal-to-noise ratio type parameter in the specification of these priors. Finally, we illustrate the applicability of the proposed state space mixed models for longitudinal binomial response data in both simulation studies and data examples.},
  doi        = {10.1007/s00362-006-0039-y},
  file       = {:czado2008 - State Space Mixed Models for Longitudinal Observations with Binary and Binomial Responses.pdf:PDF},
  groups     = {ILD, SSM, RILD},
  keywords   = {Longitudinal data, Markov chain Monte Carlo, Probit, Random effects, Regression, Seasonality, Signal-to-noise ratio},
  language   = {en},
  ranking    = {rank5},
  readstatus = {read},
  url        = {https://doi.org/10.1007/s00362-006-0039-y},
  urldate    = {2022-08-28},
}

 
@Article{joergensen1999,
  author   = {Jørgensen, B. and Lundbye-Christensen, S. and Song, P. X.-K. and Sun, L.},
  journal  = {Biometrika},
  title    = {A state space model for multivariate longitudinal count data},
  year     = {1999},
  issn     = {0006-3444},
  month    = mar,
  number   = {1},
  pages    = {169--181},
  volume   = {86},
  abstract = {We propose a nonstationary state space model for multivariate longitudinal count data driven by a latent gamma Markov process. The Poisson counts are assumed to be conditionally independent given the latent process, both over time and across categories. We consider a regression model where time-varying covariates may enter via either the Poisson model or the latent gamma process. Estimation is based on the Kalman smoother, and we consider analysis of residuals from both the Poisson model and the latent process. A reanalysis of Zeger's (1988) polio data shows that the choice between a stationary and nonstationary model is crucial for the correct assessment of the evidence of a long-term decrease in the rate of U.S. polio infection.Keywords:EM algorithm; Estimation function; Generalised linear model; Kalman filter; Kalman smoother; Latent process; Mixed Poisson distribution; Overdispersion; Regression model; Residual analysis; Time-varying covariate.},
  doi      = {10.1093/biomet/86.1.169},
  file     = {:joergensen1999 - A State Space Model for Multivariate Longitudinal Count Data.pdf:PDF},
  groups   = {SSM},
  url      = {https://doi.org/10.1093/biomet/86.1.169},
  urldate  = {2022-08-29},
}

@Article{gisev2013,
  author       = {Gisev, Natasa and Bell, J. Simon and Chen, Timothy F.},
  journal      = {Research in Social and Administrative Pharmacy},
  title        = {Interrater agreement and interrater reliability: Key concepts, approaches, and applications},
  year         = {2013},
  issn         = {1551-7411},
  month        = may,
  number       = {3},
  pages        = {330--338},
  volume       = {9},
  abstract     = {Evaluations of interrater agreement and interrater reliability can be applied to a number of different contexts and are frequently encountered in social and administrative pharmacy research. The objectives of this study were to highlight key differences between interrater agreement and interrater reliability; describe the key concepts and approaches to evaluating interrater agreement and interrater reliability; and provide examples of their applications to research in the field of social and administrative pharmacy. This is a descriptive review of interrater agreement and interrater reliability indices. It outlines the practical applications and interpretation of these indices in social and administrative pharmacy research. Interrater agreement indices assess the extent to which the responses of 2 or more independent raters are concordant. Interrater reliability indices assess the extent to which raters consistently distinguish between different responses. A number of indices exist, and some common examples include Kappa, the Kendall coefficient of concordance, Bland-Altman plots, and the intraclass correlation coefficient. Guidance on the selection of an appropriate index is provided. In conclusion, selection of an appropriate index to evaluate interrater agreement or interrater reliability is dependent on a number of factors including the context in which the study is being undertaken, the type of variable under consideration, and the number of raters making assessments.},
  doi          = {10.1016/j.sapharm.2012.04.004},
  file         = {:gisev2013 - Interrater Agreement and Interrater Reliability_ Key Concepts, Approaches, and Applications.pdf:PDF},
  groups       = {ICC, Overview, Reliability},
  keywords     = {Health services research, Research design, Reproducibility of results, Observer variation},
  langid       = {english},
  readstatus   = {read},
  shortjournal = {Research in Social and Administrative Pharmacy},
  shorttitle   = {Interrater agreement and interrater reliability},
  url          = {https://www.sciencedirect.com/science/article/pii/S1551741112000642},
  urldate      = {2022-08-29},
}

@Book{wickham2016,
  author    = {Wickham, Hadley and Grolemund, Garrett},
  publisher = {O'Reilly Media, Inc.},
  title     = {R for data science: Import, tidy, transform, visualize, and model data},
  year      = {2016},
  groups    = {R},
}

@Article{wakker1993,
  author   = {Wakker, Peter P. and Tversky, Amos},
  journal  = {Journal of Risk and Uncertainty},
  title    = {An axiomatization of cumulative prospect theory},
  year     = {1993},
  month    = {10},
  number   = {2},
  pages    = {147--175},
  volume   = {7},
  date     = {1993-10},
  doi      = {10.1007/bf01065812},
  groups   = {Prospect theory},
  langid   = {en},
  priority = {prio2},
  url      = {http://dx.doi.org/10.1007/bf01065812},
}

@Article{tversky1992,
  author     = {Amos Tversky and Daniel Kahneman},
  journal    = {Journal of Risk and Uncertainty},
  title      = {Advances in prospect theory: Cumulative representation of uncertainty},
  year       = {1992},
  month      = {sep},
  pages      = {297--323},
  volume     = {5},
  doi        = {10.1007/BF00122574},
  file       = {:tversky1992 - Advances in Prospect Theory_ Cumulative Representation of Uncertainty.pdf:PDF},
  groups     = {Prospect theory},
  readstatus = {read},
}

@Article{schmidt2005,
  author   = {Schmidt, Ulrich and Zank, Horst},
  journal  = {Journal of Risk and Uncertainty},
  title    = {What is loss aversion?},
  year     = {2005},
  month    = {03},
  number   = {2},
  pages    = {157--167},
  volume   = {30},
  date     = {2005-03},
  doi      = {10.1007/s11166-005-6564-6},
  file     = {:schmidt2005 - What Is Loss Aversion_.pdf:PDF},
  groups   = {Prospect theory},
  langid   = {en},
  priority = {prio1},
  url      = {http://dx.doi.org/10.1007/s11166-005-6564-6},
}

@Article{neilson2002,
  author  = {Neilson, William S.},
  journal = {Journal of Risk and Uncertainty},
  title   = {Comparative risk sensitivity with reference-dependent preferences},
  year    = {2002},
  number  = {2},
  pages   = {131--142},
  volume  = {24},
  date    = {2002},
  doi     = {10.1023/a:1014015926103},
  groups  = {Prospect theory},
  url     = {http://dx.doi.org/10.1023/A:1014015926103},
}

@Article{köebberling2005,
  author     = {{Köbberling}, Veronika and Wakker, Peter P.},
  journal    = {Journal of Economic Theory},
  title      = {An index of loss aversion},
  year       = {2005},
  month      = {05},
  number     = {1},
  pages      = {119--131},
  volume     = {122},
  date       = {2005-05},
  doi        = {10.1016/j.jet.2004.03.009},
  file       = {:köebberling2005 - An Index of Loss Aversion.pdf:PDF},
  groups     = {Prospect theory},
  langid     = {en},
  ranking    = {rank5},
  readstatus = {read},
  url        = {http://dx.doi.org/10.1016/j.jet.2004.03.009},
}

@Article{kahneman1979,
  author     = {Kahneman, Daniel and Tversky, Amos},
  journal    = {Econometrica},
  title      = {Prospect theory: An analysis of decision under risk},
  year       = {1979},
  month      = {03},
  number     = {2},
  pages      = {263},
  volume     = {47},
  date       = {1979-03},
  doi        = {10.2307/1914185},
  file       = {:kahneman1979 - Prospect Theory_ an Analysis of Decision under Risk.pdf:PDF},
  groups     = {Prospect theory},
  ranking    = {rank5},
  readstatus = {read},
  url        = {http://dx.doi.org/10.2307/1914185},
}

@Article{brown2021,
  author     = {Brown, Alexander L. and Imai, Taisuke and Vieider, Ferdinand and Camerer, Colin F.},
  journal    = {SSRN Electronic Journal},
  title      = {Meta-analysis of empirical estimates of loss-aversion},
  year       = {2021},
  date       = {2021},
  doi        = {10.2139/ssrn.3772089},
  file       = {:brown2021 - Meta Analysis of Empirical Estimates of Loss Aversion.pdf:PDF},
  groups     = {Prospect theory},
  langid     = {en},
  priority   = {prio1},
  readstatus = {skimmed},
  url        = {http://dx.doi.org/10.2139/ssrn.3772089},
}

@Article{bowman1999,
  author   = {Bowman, David and Minehart, Deborah and Rabin, Matthew},
  journal  = {Journal of Economic Behavior & Organization},
  title    = {Loss aversion in a consumption{\textendash}savings model},
  year     = {1999},
  month    = {02},
  number   = {2},
  pages    = {155--178},
  volume   = {38},
  date     = {1999-02},
  doi      = {10.1016/s0167-2681(99)00004-9},
  file     = {:bowman1999 - Loss Aversion in a Consumption_savings Model.pdf:PDF},
  groups   = {Prospect theory},
  langid   = {en},
  priority = {prio2},
  ranking  = {rank4},
  url      = {http://dx.doi.org/10.1016/s0167-2681(99)00004-9},
}

@Article{bleichrodt2000,
  author  = {Bleichrodt, Han and Pinto, Jose Luis},
  journal = {Management Science},
  title   = {A parameter-free elicitation of the probability weighting function in medical decision analysis},
  year    = {2000},
  month   = nov,
  number  = {11},
  pages   = {1485--1496},
  volume  = {46},
  date    = {2000-11},
  doi     = {10.1287/mnsc.46.11.1485.12086},
  file    = {:bleichrodt2000 - A Parameter Free Elicitation of the Probability Weighting Function in Medical Decision Analysis.pdf:PDF},
  groups  = {Prospect theory},
  langid  = {en},
  ranking = {rank4},
  url     = {http://dx.doi.org/10.1287/mnsc.46.11.1485.12086},
}

@Article{blake2021,
  author  = {Blake, David and Cannon, Edmund and Wright, Douglas},
  journal = {Journal of Risk and Uncertainty},
  title   = {Quantifying loss aversion: Evidence from a {UK} population survey},
  year    = {2021},
  month   = {08},
  number  = {1},
  pages   = {27--57},
  volume  = {63},
  date    = {2021-08},
  doi     = {10.1007/s11166-021-09356-7},
  file    = {:blake2021 - Quantifying Loss Aversion_ Evidence from a UK Population Survey.pdf:PDF},
  groups  = {Prospect theory},
  langid  = {en},
  url     = {http://dx.doi.org/10.1007/s11166-021-09356-7},
}

@Article{abdellaoui2016,
  author     = {Abdellaoui, Mohammed and Bleichrodt, Han and {L{\textquoteright}Haridon}, Olivier and van Dolder, Dennie},
  journal    = {Journal of Risk and Uncertainty},
  title      = {Measuring loss aversion under ambiguity: A method to make prospect theory completely observable},
  year       = {2016},
  month      = {02},
  number     = {1},
  pages      = {1--20},
  volume     = {52},
  date       = {2016-02},
  doi        = {10.1007/s11166-016-9234-y},
  file       = {:abdellaoui2016 - Measuring Loss Aversion under Ambiguity_ a Method to Make Prospect Theory Completely Observable.pdf:PDF},
  groups     = {Prospect theory},
  langid     = {en},
  ranking    = {rank5},
  readstatus = {read},
  url        = {http://dx.doi.org/10.1007/s11166-016-9234-y},
}

@Article{abdellaoui2008,
  author   = {Abdellaoui, Mohammed and Bleichrodt, Han and {L{\textquoteright}Haridon}, Olivier},
  journal  = {Journal of Risk and Uncertainty},
  title    = {A tractable method to measure utility and loss aversion under prospect theory},
  year     = {2008},
  month    = {05},
  number   = {3},
  pages    = {245--266},
  volume   = {36},
  date     = {2008-05-07},
  doi      = {10.1007/s11166-008-9039-8},
  file     = {:abdellaoui2008 - A Tractable Method to Measure Utility and Loss Aversion under Prospect Theory.pdf:PDF},
  groups   = {Prospect theory},
  langid   = {en},
  priority = {prio3},
  url      = {http://dx.doi.org/10.1007/s11166-008-9039-8},
}

@Article{abdellaoui2007,
  author     = {Abdellaoui, Mohammed and Bleichrodt, Han and Paraschiv, Corina},
  journal    = {Management Science},
  title      = {Loss aversion under prospect theory: A parameter-free measurement},
  year       = {2007},
  month      = {10},
  number     = {10},
  pages      = {1659--1674},
  volume     = {53},
  date       = {2007-10},
  doi        = {10.1287/mnsc.1070.0711},
  file       = {:abdellaoui2007 - Loss Aversion under Prospect Theory_ a Parameter Free Measurement.pdf:PDF;:abdellaoui2007 - Supplemental Material.pdf:PDF},
  groups     = {Prospect theory},
  langid     = {en},
  ranking    = {rank5},
  readstatus = {read},
  url        = {http://dx.doi.org/10.1287/mnsc.1070.0711},
}

@Article{Abdellaoui2005,
  author     = {Abdellaoui, Mohammed and Vossmann, Frank and Weber, Martin},
  journal    = {Management Science},
  title      = {Choice-based elicitation and decomposition of decision weights for gains and losses under uncertainty},
  year       = {2005},
  month      = {09},
  number     = {9},
  pages      = {1384--1399},
  volume     = {51},
  date       = {2005-09},
  doi        = {10.1287/mnsc.1050.0388},
  file       = {:abdellaoui2005 - Choice Based Elicitation and Decomposition of Decision Weights for Gains and Losses under Uncertainty.pdf:PDF},
  groups     = {Prospect theory},
  langid     = {en},
  ranking    = {rank4},
  readstatus = {read},
  url        = {http://dx.doi.org/10.1287/mnsc.1050.0388},
}

@Article{buerkner2017,
  author = {{Bürkner}, Paul-Christian},
  title  = {{brms}: An {R} package for {Bayesian} multilevel models using {Stan}},
  year   = {2017},
  volume = {80},
  date   = {2017},
  doi    = {10.18637/jss.v080.i01},
  groups = {R},
}

 
@Article{abdellaoui2007a,
  author       = {Abdellaoui, Mohammed and Barrios, Carolina and Wakker, Peter P.},
  journal      = {Journal of Econometrics},
  title        = {Reconciling introspective utility with revealed preference: Experimental arguments based on prospect theory},
  year         = {2007},
  issn         = {0304-4076},
  month        = may,
  number       = {1},
  pages        = {356--378},
  volume       = {138},
  abstract     = {In an experiment, choice-based (revealed-preference) utility of money is derived from choices under risk, and choiceless (non-revealed-preference) utility from introspective strength-of-preference judgments. The well-known inconsistencies of risky utility under expected utility are resolved under prospect theory, yielding one consistent cardinal utility index for risky choice. Remarkably, however, this cardinal index also agrees well with the choiceless utilities, suggesting a relation between a choice-based and a choiceless concept. Such a relation implies that introspective judgments can provide useful data for economics, and can reinforce the revealed-preference paradigm. This finding sheds new light on the classical debate on ordinal versus cardinal utility.},
  doi          = {10.1016/j.jeconom.2006.05.025},
  file         = {:abdellaoui2007a - Reconciling Introspective Utility with Revealed Preference_ Experimental Arguments Based on Prospect Theory.pdf:PDF},
  groups       = {Prospect theory},
  keywords     = {Cardinal utility, Ordinal revolution, Prospect theory, Risky utility, Strength of preference},
  langid       = {english},
  priority     = {prio2},
  series       = {50th Anniversary Econometric Institute},
  shortjournal = {Journal of Econometrics},
  shorttitle   = {Reconciling introspective utility with revealed preference},
  url          = {https://www.sciencedirect.com/science/article/pii/S0304407606000984},
  urldate      = {2022-09-09},
}

@Article{anders2018,
  author  = {Anders, Royce and Alario, F. Xavier and Batchelder, William H.},
  journal = {Cross-Cultural Research},
  title   = {Consensus analysis for populations with latent subgroups: Applying multicultural consensus theory and model-based clustering with {CCTpack}},
  year    = {2018},
  issn    = {1069-3971},
  number  = {3},
  pages   = {274--308},
  volume  = {52},
  doi     = {10.1177/1069397117727500},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1177/1069397117727500},
}

@Article{anders2012,
  author  = {Anders, Royce and Batchelder, William H.},
  journal = {Journal of Mathematical Psychology},
  title   = {Cultural consensus theory for multiple consensus truths},
  year    = {2012},
  issn    = {0022-2496},
  number  = {6},
  pages   = {452--469},
  volume  = {56},
  doi     = {10.1016/j.jmp.2013.01.004},
  groups  = {CCT},
  url     = {http://www.sciencedirect.com/science/article/pii/S0022249613000114},
}

@Article{anders2015,
  author  = {Anders, Royce and Batchelder, William H.},
  journal = {Psychometrika},
  title   = {Cultural consensus theory for the ordinal data case},
  year    = {2015},
  issn    = {0033-3123},
  number  = {1},
  pages   = {151--181},
  volume  = {80},
  doi     = {10.1007/s11336-013-9382-9},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1007/s11336-013-9382-9},
}

@Article{anders2014,
  author  = {Anders, Royce and Oravecz, Z. and Batchelder, William H.},
  journal = {Journal of Mathematical Psychology},
  title   = {Cultural consensus theory for continuous responses: A latent appraisal model for information pooling},
  year    = {2014},
  issn    = {0022-2496},
  pages   = {1--13},
  volume  = {61},
  doi     = {10.1016/j.jmp.2014.06.001},
  groups  = {CCT},
  url     = {http://www.sciencedirect.com/science/article/pii/S0022249614000406},
}

@Article{ando2007,
  author  = {Ando, Tomohiro},
  journal = {Biometrika},
  title   = {Bayesian predictive information criterion for the evaluation of hierarchical {B}ayesian and empirical {B}ayes models},
  year    = {2007},
  issn    = {0006-3444},
  number  = {2},
  pages   = {443--458},
  volume  = {94},
  doi     = {10.1093/biomet/asm017},
  groups  = {CCT},
  url     = {https://doi.org/10.1093/biomet/asm017},
}

@Article{assfalg2020,
  author  = {Aßfalg, André and Klauer, Karl Christoph},
  journal = {Journal of Mathematical Psychology},
  title   = {Consensus theory for multiple latent traits and consensus groups},
  year    = {2020},
  issn    = {0022-2496},
  pages   = {102374},
  volume  = {97},
  doi     = {10.1016/j.jmp.2020.102374},
  groups  = {CCT},
  url     = {http://www.sciencedirect.com/science/article/pii/S0022249620300420},
}

@Article{batchelder2012,
  author  = {Batchelder, William H. and Anders, Royce},
  journal = {Journal of Mathematical Psychology},
  title   = {Cultural consensus theory: Comparing different concepts of cultural truth},
  year    = {2012},
  issn    = {0022-2496},
  number  = {5},
  pages   = {316--332},
  volume  = {56},
  doi     = {10.1016/j.jmp.2012.06.002},
  groups  = {CCT},
  url     = {http://www.sciencedirect.com/science/article/pii/S0022249612000715},
}

@InCollection{batchelder2018,
  author    = {Batchelder, William H. and Anders, Royce and Oravecz, Zita},
  booktitle = {Stevens' handbook of experimental psychology and cognitive neuroscience},
  publisher = {Wiley},
  title     = {Cultural consensus theory},
  year      = {2018},
  edition   = {4th},
  editor    = {Wagenmakers, Eric-Jan},
  pages     = {201--264},
  volume    = {5},
  doi       = {10.1002/9781119170174.epcn506},
  groups    = {CCT},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119170174.epcn506},
}

@InCollection{batchelder1986,
  author    = {Batchelder, William H. and Romney, A. Kimball},
  booktitle = {Information pooling and group decision making},
  publisher = {JAI Press},
  title     = {The statistical analysis of a general {C}ondorcet model for dichotomous choice situations},
  year      = {1986},
  editor    = {Grofman, B. and Owen, G.},
  pages     = {103--112},
  groups    = {CCT},
}

@Article{batchelder1988,
  author  = {Batchelder, William H. and Romney, A. Kimball},
  journal = {Psychometrika},
  title   = {Test theory without an answer key},
  year    = {1988},
  issn    = {0033-3123},
  number  = {1},
  pages   = {71--92},
  volume  = {53},
  doi     = {10.1007/bf02294195},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1007/BF02294195},
}

@Article{broadbent1966,
  author  = {Broadbent, D. E.},
  journal = {The Journal of the Acoustical Society of America},
  title   = {Two‐state threshold model and rating‐scale experiments},
  year    = {1966},
  issn    = {0001-4966},
  number  = {1},
  pages   = {244--245},
  volume  = {40},
  doi     = {10.1121/1.1910047},
  groups  = {CCT},
}

@Article{comrey1962,
  author  = {Comrey, Andrew L.},
  journal = {Psychological Reports},
  title   = {The minimum residual method of factor analysis},
  year    = {1962},
  issn    = {0033-2941},
  number  = {1},
  pages   = {15--18},
  volume  = {11},
  doi     = {10.2466/pr0.1962.11.1.15},
  groups  = {CCT},
}

@Article{deonovic2017,
  author    = {Deonovic, Benjamin E. and Smith, Brian J.},
  journal   = {arXiv:1706.04919},
  title     = {Convergence diagnostics for {MCMC} draws of a categorical variable},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/arxiv.1706.04919},
  groups    = {CCT},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1706.04919},
}

@Article{gelfand1990,
  author  = {Gelfand, Alan E. and Smith, Adrian F. M.},
  journal = {Journal of the American Statistical Association},
  title   = {Sampling-based approaches to calculating marginal densities},
  year    = {1990},
  issn    = {0162-1459},
  number  = {410},
  pages   = {398--409},
  volume  = {85},
  doi     = {10.1080/01621459.1990.10476213},
  groups  = {CCT},
  url     = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1990.10476213},
}

@Book{gelman2013,
  author    = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  publisher = {Chapman and Hall/CRC},
  title     = {Bayesian data analysis},
  year      = {2013},
  edition   = {3rd},
  isbn      = {9781439840955},
  month     = nov,
  file      = {:gelman2013 - Bayesian Data Analysis.pdf:PDF;:gelman2013 - Solutions3.pdf:PDF},
  groups    = {CCT, Bayesian},
}

@Article{gelman1992,
  author  = {Gelman, Andrew and Rubin, Donald B.},
  journal = {Statistical Science},
  title   = {Inference from iterative simulation using multiple sequences},
  year    = {1992},
  number  = {4},
  pages   = {457--472},
  volume  = {7},
  doi     = {10.1214/ss/1177011136},
  groups  = {CCT},
  url     = {https://doi.org/10.1214/ss/1177011136},
}

@Article{geman1984,
  author  = {Geman, S. and Geman, D.},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {Stochastic relaxation, {G}ibbs distributions, and the {B}ayesian restoration of images},
  year    = {1984},
  issn    = {1939-3539},
  number  = {6},
  pages   = {721--741},
  volume  = {PAMI-6},
  doi     = {10.1109/TPAMI.1984.4767596},
  groups  = {CCT},
}

@Book{green1966,
  author    = {Green, David Marvin and Swets, John A.},
  publisher = {John Wiley},
  title     = {Signal detection theory and psychophysics},
  year      = {1966},
  groups    = {CCT},
}

@Article{hruschka2008,
  author  = {Hruschka, Daniel J. and Sibley, Lynn M. and Kalim, Nahid and Edmonds, Joyce K.},
  journal = {Field Methods},
  title   = {When there is more than one answer key: Cultural theories of postpartum hemorrhage in {M}atlab, {B}angladesh},
  year    = {2008},
  issn    = {1525-822X},
  number  = {4},
  pages   = {315--337},
  volume  = {20},
  doi     = {10.1177/1525822X08321315},
  groups  = {CCT},
  url     = {https://doi.org/10.1177/1525822X08321315},
}

@Article{hsu2015,
  author  = {Hsu, Yung-Fong and Doble, Christopher W.},
  journal = {British Journal of Mathematical and Statistical Psychology},
  title   = {A threshold theory account of psychometric functions with response confidence under the balance condition},
  year    = {2015},
  issn    = {0007-1102},
  number  = {1},
  pages   = {158--177},
  volume  = {68},
  doi     = {10.1111/bmsp.12040},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1111/bmsp.12040},
}

@Book{jeffreys1998,
  author    = {Jeffreys, Harold},
  publisher = {OUP Oxford},
  title     = {The theory of probability},
  year      = {1998},
  edition   = {3rd},
  isbn      = {0191589675},
  groups    = {CCT},
}

@Article{karabatsos2003,
  author  = {Karabatsos, George and Batchelder, William H.},
  journal = {Psychometrika},
  title   = {Markov chain estimation for test theory without an answer key},
  year    = {2003},
  issn    = {0033-3123},
  number  = {3},
  pages   = {373--389},
  volume  = {68},
  doi     = {10.1007/bf02294733},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1007/BF02294733},
}

@InCollection{karl2018,
  author    = {Karl, David Kellen and Klauer, Christoph},
  booktitle = {Stevens' Handbook of Experimental Psychology and Cognitive Neuroscience},
  publisher = {Wiley},
  title     = {Elementary signal detection and threshold theory},
  year      = {2018},
  edition   = {4th},
  editor    = {Wagenmakers, Eric-Jan},
  pages     = {1--39},
  volume    = {5},
  doi       = {10.1002/9781119170174.epcn505},
  groups    = {CCT},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119170174.epcn505},
}

@Article{kass1995,
  author  = {Kass, Robert E. and Raftery, Adrian E.},
  journal = {Journal of the American Statistical Association},
  title   = {Bayes factors},
  year    = {1995},
  issn    = {0162-1459},
  number  = {430},
  pages   = {773--795},
  volume  = {90},
  doi     = {10.1080/01621459.1995.10476572},
  groups  = {CCT},
}

@Article{krantz1969,
  author  = {Krantz, David H.},
  journal = {Psychological Review},
  title   = {Threshold theories of signal detection},
  year    = {1969},
  issn    = {1939-1471(Electronic),0033-295X(Print)},
  number  = {3},
  pages   = {308--324},
  volume  = {76},
  doi     = {10.1037/h0027238},
  groups  = {CCT},
}

@Article{lee2011,
  author  = {Lee, Michael D.},
  journal = {Journal of Mathematical Psychology},
  title   = {How cognitive modeling can benefit from hierarchical {B}ayesian models},
  year    = {2011},
  issn    = {0022-2496},
  number  = {1},
  pages   = {1--7},
  volume  = {55},
  doi     = {10.1016/j.jmp.2010.08.013},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1016/j.jmp.2010.08.013},
}

@Book{lee2014,
  author    = {Lee, Michael D. and Wagenmakers, Eric-Jan},
  publisher = {Cambridge University Press},
  title     = {Bayesian cognitive modeling: A practical course},
  year      = {2014},
  isbn      = {1107653916},
  groups    = {CCT},
}

@Article{luce1963,
  author  = {Luce, R. Duncan},
  journal = {Psychological Review},
  title   = {A threshold theory for simple detection experiments},
  year    = {1963},
  issn    = {1939-1471(Electronic),0033-295X(Print)},
  number  = {1},
  pages   = {61--79},
  volume  = {70},
  doi     = {10.1037/h0039723},
  groups  = {CCT},
}

@Book{macmillan2004,
  author    = {Macmillan, Neil A. and Creelman, C. Douglas},
  publisher = {Psychology press},
  title     = {Detection theory: A user's guide},
  year      = {2004},
  edition   = {2nd},
  isbn      = {1135634572},
  doi       = {10.4324/9781410611147},
  groups    = {CCT},
}

@InCollection{meyer2016,
  author    = {Meyer, Renate},
  booktitle = {Wiley {S}tats{R}ef: Statistics reference online},
  publisher = {John Wiley \& Sons, Ltd.},
  title     = {Deviance information criterion ({DIC})},
  year      = {2016},
  editor    = {Balakrishnan, N. and Colton, T. and Everitt, B. and Piegorsch, W. and Ruggeri, F. and Teugels, J.},
  pages     = {1--6},
  doi       = {10.1002/9781118445112.stat07878},
  groups    = {CCT},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat07878},
}

@Article{nachmias1963,
  author  = {Nachmias, Jacob and Steinman, Robert M.},
  journal = {Journal of the Optical Society of America},
  title   = {Study of absolute visual detection by the rating-scale method},
  year    = {1963},
  number  = {10},
  pages   = {1206--1213},
  volume  = {53},
  doi     = {10.1364/JOSA.53.001206},
  groups  = {CCT},
  url     = {http://www.osapublishing.org/abstract.cfm?URI=josa-53-10-1206},
}

@Article{oravecz2015,
  author  = {Oravecz, Zita and Anders, Royce and Batchelder, William H.},
  journal = {Psychometrika},
  title   = {Hierarchical {B}ayesian modeling for test theory without an answer key},
  year    = {2015},
  issn    = {0033-3123},
  number  = {2},
  pages   = {341--364},
  volume  = {80},
  doi     = {10.1007/s11336-013-9379-4},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1007/s11336-013-9379-4},
}

@InProceedings{plummer2003,
  author    = {Plummer, Martyn},
  booktitle = {Proceedings of the 3rd International Workshop on Distributed Statistical Computing},
  title     = {{JAGS}: A program for analysis of {B}ayesian graphical models using {G}ibbs sampling},
  year      = {2003},
  pages     = {1--10},
  publisher = {Vienna, Austria},
  volume    = {124},
  groups    = {CCT},
  url       = {https://www.r-project.org/conferences/DSC-2003/},
}

@Article{plummer2008,
  author  = {Plummer, Martyn},
  journal = {Biostatistics},
  title   = {Penalized loss functions for {B}ayesian model comparison},
  year    = {2008},
  issn    = {1465-4644},
  number  = {3},
  pages   = {523--539},
  volume  = {9},
  doi     = {10.1093/biostatistics/kxm049},
  groups  = {CCT},
  url     = {https://doi.org/10.1093/biostatistics/kxm049},
}

@Manual{plummer2019,
  title   = {rjags: {Bayesian} graphical models using {MCMC}},
  author  = {Plummer, Martyn},
  note    = {R package version 4-10},
  year    = {2019},
  groups  = {CCT},
  journal = {R package version},
  number  = {6},
  url     = {https://CRAN.R-project.org/package=rjags},
  volume  = {4},
}

@Manual{rct2020,
  title        = {R: A language and environment for statistical computing},
  address      = {Vienna, Austria},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  year         = {2020},
  groups       = {CCT},
  url          = {https://www.R-project.org},
}

@Book{rasch1960,
  author    = {Rasch, Georg},
  publisher = {Nielsen \& Lydiche},
  title     = {Studies in mathematical psychology: I {P}robabilistic models for some intelligence and attainment tests},
  year      = {1960},
  address   = {Oxford},
  groups    = {CCT},
}

@Article{redner1984,
  author  = {Redner, Richard A. and Walker, Homer F.},
  journal = {SIAM Review},
  title   = {Mixture densities, maximum likelihood and the {EM} algorithm},
  year    = {1984},
  issn    = {0036-1445},
  number  = {2},
  pages   = {195--239},
  volume  = {26},
  doi     = {10.1137/1026034},
  groups  = {CCT},
  url     = {https://doi.org/10.1137/1026034},
}

@Manual{revelle2020,
  title        = {{psych}: Procedures for psychological, psychometric, and personality research},
  address      = {Evanston, Illinois},
  author       = {William Revelle},
  note         = {R package version 2.0.9},
  organization = {Northwestern University},
  year         = {2020},
  groups       = {CCT},
  journal      = {The comprehensive R archive network},
  url          = {https://CRAN.R-project.org/package=psych},
}

@Article{romney1987,
  author  = {Romney, A. Kimball and Batchelder, William H. and Weller, Susan C.},
  journal = {American Behavioral Scientist},
  title   = {Recent applications of cultural consensus theory},
  year    = {1987},
  issn    = {0002-7642},
  number  = {2},
  pages   = {163--177},
  volume  = {31},
  doi     = {10.1177/000276487031002003},
  groups  = {CCT},
}

@Article{romney1986,
  author  = {Romney, A. Kimball and Weller, Susan C. and Batchelder, William H.},
  journal = {American Anthropologist},
  title   = {Culture as consensus: A theory of culture and informant accuracy},
  year    = {1986},
  issn    = {0002-7294},
  number  = {2},
  pages   = {313--338},
  volume  = {88},
  doi     = {10.1525/aa.1986.88.2.02a00020},
  groups  = {CCT},
}

@Article{rouder2005,
  author  = {Rouder, Jeffrey N. and Lu, Jun},
  journal = {Psychonomic Bulletin \& Review},
  title   = {An introduction to {B}ayesian hierarchical models with an application in the theory of signal detection},
  year    = {2005},
  issn    = {1069-9384},
  number  = {4},
  pages   = {573--604},
  volume  = {12},
  doi     = {10.3758/bf03196750},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.3758/bf03196750},
}

@Article{rouder2009,
  author  = {Rouder, Jeffrey N. and Morey, Richard D.},
  journal = {Psychological Review},
  title   = {The nature of psychological thresholds},
  year    = {2009},
  issn    = {1939-1471(Electronic),0033-295X(Print)},
  pages   = {655--660},
  volume  = {116},
  doi     = {10.1037/a0016413},
  groups  = {CCT},
}

@Article{spearman1904,
  author  = {Spearman, C.},
  journal = {The American Journal of Psychology},
  title   = {'{G}eneral intelligence,' objectively determined and measured},
  year    = {1904},
  issn    = {0002-9556
1939-8298},
  number  = {2},
  pages   = {201-293},
  volume  = {15},
  doi     = {10.1037/11491-006},
  groups  = {CCT},
  url     = {https://search.ebscohost.com/login.aspx?direct=true&db=psyh&AN=1926-00296-001&site=ehost-live&scope=site},
}

@Article{stephens2000,
  author  = {Stephens, Matthew},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  title   = {Dealing with label switching in mixture models},
  year    = {2000},
  issn    = {1369-7412},
  number  = {4},
  pages   = {795-809},
  volume  = {62},
  doi     = {10.1111/1467-9868.00265},
  groups  = {CCT},
  url     = {https://dx.doi.org/10.1111/1467-9868.00265},
}

@Manual{su2020,
  title  = {{R2jags}: Using {R} to run `{JAGS}'},
  author = {Su, Yu-Sung and Yajima, Masanao},
  note   = {R package version 0.6-1},
  year   = {2020},
  groups = {CCT},
  url    = {http://CRAN.R-project.org/package=R2jags},
}

@Article{watanabe2010,
  author  = {Watanabe, Sumio},
  journal = {Journal of Machine Learning Research},
  title   = {Asymptotic equivalence of {B}ayes cross validation and widely applicable information criterion in singular learning theory},
  year    = {2010},
  issn    = {1532-4435},
  number  = {12},
  pages   = {3571--3594},
  volume  = {11},
  groups  = {CCT},
  url     = {https://jmlr.org/papers/v11/watanabe10a.html},
}

@Article{watson1965,
  author  = {Watson, Charles S. and Bourbon, Walter T.},
  journal = {The Journal of the Acoustical Society of America},
  title   = {Rating scales and two‐state threshold models},
  year    = {1965},
  issn    = {0001-4966},
  number  = {4},
  pages   = {667--668},
  volume  = {38},
  doi     = {10.1121/1.1909772},
  groups  = {CCT},
}

@Article{koval2013,
  author     = {Koval, Peter and Pe, Madeline L. and Meers, Kristof and Kuppens, Peter},
  journal    = {Emotion},
  title      = {Affect dynamics in relation to depressive symptoms: Variable, unstable or inert?},
  year       = {2013},
  month      = {dec},
  number     = {6},
  pages      = {1132--1141},
  volume     = {13},
  doi        = {10.1037/a0033579},
  file       = {:koval2013 - Affect Dynamics in Relation to Depressive Symptoms_ Variable, Unstable or Inert_.pdf:PDF},
  groups     = {RILD, Affect},
  publisher  = {American Psychological Association ({APA})},
  ranking    = {rank2},
  readstatus = {read},
}

@Article{russell1989,
  author    = {Russell, James A. and Weiss, Anna and Mendelsohn, Gerald A.},
  journal   = {Journal of Personality and Social Psychology},
  title     = {Affect grid: A single-item scale of pleasure and arousal.},
  year      = {1989},
  month     = {sep},
  number    = {3},
  pages     = {493--502},
  volume    = {57},
  doi       = {10.1037/0022-3514.57.3.493},
  file      = {:russell1989 - Affect Grid_ a Single Item Scale of Pleasure and Arousal..pdf:PDF},
  groups    = {Affect},
  priority  = {prio3},
  publisher = {American Psychological Association ({APA})},
}

@Article{shrout1979,
  author     = {Shrout, Patrick E. and Fleiss, Joseph L.},
  journal    = {Psychological Bulletin},
  title      = {Intraclass correlations: Uses in assessing rater reliability.},
  year       = {1979},
  number     = {2},
  pages      = {420--428},
  volume     = {86},
  doi        = {10.1037/0033-2909.86.2.420},
  file       = {:Bibliography/shrout1979 - Intraclass Correlations_ Uses in Assessing Rater Reliability..pdf:PDF},
  groups     = {ICC, Reliability},
  publisher  = {American Psychological Association ({APA})},
  readstatus = {skimmed},
}

 
@Article{zhang2018,
  author   = {Zhang, Duo and Wang, Min},
  journal  = {Statistics \& Probability Letters},
  title    = {Objective {Bayesian} inference for the intraclass correlation coefficient in linear models},
  year     = {2018},
  issn     = {0167-7152},
  month    = jun,
  pages    = {292--296},
  volume   = {137},
  abstract = {We outline objective Bayesian testing procedure for the intraclass correlation coefficient in linear models. For it, we derive the Bayes factors based on the divergence-based priors, which have unidimensional integral expressions and can thus be easily approximated numerically.},
  doi      = {10.1016/j.spl.2018.02.004},
  file     = {:zhang2018 - Objective Bayesian Inference for the Intraclass Correlation Coefficient in Linear Models.pdf:PDF;:zhang2018 - Supplement.pdf:PDF},
  groups   = {ICC, Reliability},
  keywords = {Bayes factor, Divergence-based prior, Hypothesis testing, Intraclass model, Objective priors},
  language = {en},
  ranking  = {rank3},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167715218300488},
  urldate  = {2022-10-17},
}

 
@Article{mulder2019,
  author    = {Mulder, Joris and Fox, Jean-Paul},
  journal   = {Bayesian Analysis},
  title     = {Bayes factor testing of multiple intraclass correlations},
  year      = {2019},
  issn      = {1936-0975, 1931-6690},
  month     = jun,
  number    = {2},
  pages     = {521--552},
  volume    = {14},
  abstract  = {The intraclass correlation plays a central role in modeling hierarchically structured data, such as educational data, panel data, or group-randomized trial data. It represents relevant information concerning the between-group and within-group variation. Methods for Bayesian hypothesis tests concerning the intraclass correlation are proposed to improve decision making in hierarchical data analysis and to assess the grouping effect across different group categories. Estimation and testing methods for the intraclass correlation coefficient are proposed under a marginal modeling framework where the random effects are integrated out. A class of stretched beta priors is proposed on the intraclass correlations, which is equivalent to shifted F priors for the between groups variances. Through a parameter expansion it is shown that this prior is conditionally conjugate under the marginal model yielding efficient posterior computation. A special improper case results in accurate coverage rates of the credible intervals even for minimal sample size and when the true intraclass correlation equals zero. Bayes factor tests are proposed for testing multiple precise and order hypotheses on intraclass correlations. These tests can be used when prior information about the intraclass correlations is available or absent. For the noninformative case, a generalized fractional Bayes approach is developed. The method enables testing the presence and strength of grouped data structures without introducing random effects. The methodology is applied to a large-scale survey study on international mathematics achievement at fourth grade to test the heterogeneity in the clustering of students in schools across countries and assessment cycles.},
  doi       = {10.1214/18-BA1115},
  file      = {:mulder2019 - Bayes Factor Testing of Multiple Intraclass Correlations.pdf:PDF},
  groups    = {ICC, Reliability},
  keywords  = {Bayes factors, hierarchical models, Intraclass correlations, shifted F priors, stretched beta priors},
  publisher = {International Society for Bayesian Analysis},
  ranking   = {rank5},
  url       = {https://projecteuclid.org/journals/bayesian-analysis/volume-14/issue-2/Bayes-Factor-Testing-of-Multiple-Intraclass-Correlations/10.1214/18-BA1115.full},
  urldate   = {2022-10-23},
}

 
@Article{ionan2014,
  author       = {Ionan, Alexei C. and Polley, Mei-Yin C. and {McShane}, Lisa M. and Dobbin, Kevin K.},
  journal      = {{BMC} Medical Research Methodology},
  title        = {Comparison of confidence interval methods for an intra-class correlation coefficient ({ICC})},
  year         = {2014},
  issn         = {1471-2288},
  month        = nov,
  number       = {1},
  pages        = {121},
  volume       = {14},
  abstract     = {The intraclass correlation coefficient ({ICC}) is widely used in biomedical research to assess the reproducibility of measurements between raters, labs, technicians, or devices. For example, in an inter-rater reliability study, a high {ICC} value means that noise variability (between-raters and within-raters) is small relative to variability from patient to patient. A confidence interval or Bayesian credible interval for the {ICC} is a commonly reported summary. Such intervals can be constructed employing either frequentist or Bayesian methodologies.},
  doi          = {10.1186/1471-2288-14-121},
  file         = {:ionan2014 - Comparison of Confidence Interval Methods for an Intra Class Correlation Coefficient (ICC).pdf:PDF;:ionan2014 - Additional File 1.pdf:PDF},
  groups       = {ICC, Reliability},
  keywords     = {Confidence interval, Credible interval, Generalized confidence interval, Intraclass correlation coefficient, Modified large sample},
  langid       = {english},
  ranking      = {rank5},
  readstatus   = {read},
  shortjournal = {{BMC} Med Res Methodol},
  url          = {https://doi.org/10.1186/1471-2288-14-121},
  urldate      = {2022-10-23},
}

 
@Article{feng2014,
  author    = {Feng, Dai and Svetnik, Vladimir and Coimbra, Alexandre and Baumgartner, Richard},
  journal   = {Journal of Biopharmaceutical Statistics},
  title     = {A comparison of confidence interval methods for the concordance correlation coefficient and intraclass correlation coefficient with small number of raters},
  year      = {2014},
  issn      = {1054-3406},
  month     = mar,
  number    = {2},
  pages     = {272--293},
  volume    = {24},
  abstract  = {The intraclass correlation coefficient ({ICC}) with fixed raters or, equivalently, the concordance correlation coefficient ({CCC}) for continuous outcomes is a widely accepted aggregate index of agreement in settings with small number of raters. Quantifying the precision of the {CCC} by constructing its confidence interval ({CI}) is important in early drug development applications, in particular in qualification of biomarker platforms. In recent years, there have been several new methods proposed for construction of {CIs} for the {CCC}, but their comprehensive comparison has not been attempted. The methods consisted of the delta method and jackknifing with and without Fisher's Z-transformation, respectively, and Bayesian methods with vague priors. In this study, we carried out a simulation study, with data simulated from multivariate normal as well as heavier tailed distribution (t-distribution with 5 degrees of freedom), to compare the state-of-the-art methods for assigning {CI} to the {CCC}. When the data are normally distributed, the jackknifing with Fisher's Z-transformation ({JZ}) tended to provide superior coverage and the difference between it and the closest competitor, the Bayesian method with the Jeffreys prior was in general minimal. For the nonnormal data, the jackknife methods, especially the {JZ} method, provided the coverage probabilities closest to the nominal in contrast to the others which yielded overly liberal coverage. Approaches based upon the delta method and Bayesian method with conjugate prior generally provided slightly narrower intervals and larger lower bounds than others, though this was offset by their poor coverage. Finally, we illustrated the utility of the {CIs} for the {CCC} in an example of a wake after sleep onset ({WASO}) biomarker, which is frequently used in clinical sleep studies of drugs for treatment of insomnia.},
  doi       = {10.1080/10543406.2013.863780},
  file      = {:feng2014 - A Comparison of Confidence Interval Methods for the Concordance Correlation Coefficient and Intraclass Correlation Coefficient with Small Number of Raters.pdf:PDF},
  groups    = {ICC, Reliability},
  keywords  = {Bayesian method, Concordance correlation coefficient, Confidence interval, Delta method, Intraclass correlation coefficient with fixed raters, Jackknife},
  pmid      = {24605969},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/10543406.2013.863780},
  urldate   = {2022-10-23},
}

@Article{chung1998,
  author     = {Chung, Younshik and Dey, Dipak K.},
  journal    = {Communications in Statistics - Theory and Methods},
  title      = {Bayesian approach to estimation of intraclass correlation using reference prior},
  year       = {1998},
  issn       = {0361-0926},
  month      = jan,
  number     = {9},
  pages      = {2241--2255},
  volume     = {27},
  abstract   = {For the balanced variance component model when the intraclass correlation coefficient is of interest, Bayesian analysis is often appropriate. Berger and Bernardo’s (1992a) grouped ordering reference prior approach is used to analyze this model. The reference priors are developed and compared for the posterior inference with real and simulated data. We examine whether the reference priors satisfy the probability-matching criterion. Further, the reference prior is shown to be good in the sense of correct frequentist coverage probability of the posterior quantile.},
  doi        = {10.1080/03610929808832225},
  file       = {:chung1998 - Bayesian Approach to Estimation of Intraclass Correlation Using Reference Prior.pdf:PDF},
  groups     = {ICC, Reliability},
  keywords   = {Prequentist coverage probability, intraclass correlation, jeffreysrsquo;s prior, matching prior, reference prior, variance component model},
  publisher  = {Taylor \& Francis},
  readstatus = {skimmed},
  url        = {https://doi.org/10.1080/03610929808832225},
  urldate    = {2022-10-24},
}

 
@Article{asparouhov2020,
  author    = {Asparouhov, Tihomir and Muthén, Bengt},
  journal   = {Structural Equation Modeling: A Multidisciplinary Journal},
  title     = {Comparison of models for the analysis of intensive longitudinal data},
  year      = {2020},
  issn      = {1070-5511},
  month     = mar,
  number    = {2},
  pages     = {275--297},
  volume    = {27},
  abstract  = {We discuss the differences between several intensive longitudinal data models. The dynamic structural equation model ({DSEM}), the residual dynamic structural equation model ({RDSEM}) and the repeated measures longitudinal model are compared in several simulation studies. We show that the {DIC} can be used to select the correct modeling framework. We discuss the consequences of incomplete or incorrect modeling for the predictors in multilevel time series models. We also illustrate the advantages of the Bayesian estimation over the {REML} estimation for models with categorical data, subject-specific autocorrelations, and subject-specific residual variances. Dynamic factor analysis models are discussed where autoregressive relations occur not only for the factors but also for the residuals of the measurement variables. The models are also illustrated with an empirical example.},
  doi       = {10.1080/10705511.2019.1626733},
  file      = {:asparouhov2020 - Comparison of Models for the Analysis of Intensive Longitudinal Data.pdf:PDF},
  groups    = {ILD},
  keywords  = {dynamic structural equation models, repeated measures longitudinal models, residual dynamic structural equation models, restricted maximum likelihood estimation},
  publisher = {Routledge},
  url       = {https://doi.org/10.1080/10705511.2019.1626733},
  urldate   = {2022-10-25},
}

 
@Article{ariens2020,
  author       = {Ariens, Sigert and Ceulemans, Eva and Adolf, Janne K.},
  journal      = {Journal of Psychosomatic Research},
  title        = {Time series analysis of intensive longitudinal data in psychosomatic research: A methodological overview},
  year         = {2020},
  issn         = {0022-3999},
  month        = oct,
  pages        = {110191},
  volume       = {137},
  abstract     = {Time series analysis of intensive longitudinal data provides the psychological literature with a powerful tool for assessing how psychological processes evolve through time. Recent applications in the field of psychosomatic research have provided insights into the dynamical nature of the relationship between somatic symptoms, physiological measures, and emotional states. These promising results highlight the intrinsic value of employing time series analysis, although application comes with some important challenges. This paper aims to present an approachable, non-technical overview of the state of the art on these challenges and the solutions that have been proposed, with emphasis on application towards psychosomatic hypotheses. Specifically, we elaborate on issues related to measurement intervals, the number and nature of the variables used in the analysis, modeling stable and changing processes, concurrent relationships, and extending time series analysis to incorporate the data of multiple individuals. We also briefly discuss some general modeling issues, such as lag-specification, sample size and time series length, and the role of measurement errors. We hope to arm applied researchers with an overview from which to select appropriate techniques from the ever growing variety of time series analysis approaches.},
  doi          = {10.1016/j.jpsychores.2020.110191},
  file         = {:ariens2020 - Time Series Analysis of Intensive Longitudinal Data in Psychosomatic Research_ a Methodological Overview.pdf:PDF},
  groups       = {ILD},
  keywords     = {Time series analysis, Intensive longitudinal data, Vector autoregressive modeling},
  langid       = {english},
  ranking      = {rank3},
  readstatus   = {read},
  shortjournal = {Journal of Psychosomatic Research},
  shorttitle   = {Time series analysis of intensive longitudinal data in psychosomatic research},
  url          = {https://www.sciencedirect.com/science/article/pii/S0022399920307534},
  urldate      = {2022-10-25},
}

 
@Book{kim1999,
  author     = {Kim, Chang-Jin and Nelson, Charles R.},
  publisher  = {The {MIT} Press},
  title      = {State-space models with regime switching: Classical and gibbs-sampling approaches with applications},
  year       = {1999},
  volume     = {1},
  abstract   = {Both state-space models and Markov switching models have been highly productive paths for empirical research in macroeconomics and finance. This book presents recent advances in econometric methods that make feasible the estimation of models that have both features. One approach, in the classical framework, approximates the likelihood function; the other, in the Bayesian framework, uses Gibbs-sampling to simulate posterior distributions from data. The authors present numerous applications of these approaches in detail: decomposition of time series into trend and cycle, a new index of coincident economic indicators, approaches to modeling monetary policy uncertainty, Friedman's "plucking" model of recessions, the detection of turning points in the business cycle and the question of whether booms and recessions are duration-dependent, state-space models with heteroskedastic disturbances, fads and crashes in financial markets, long-run real exchange rates, and mean reversion in asset returns.},
  file       = {:kim1999 - State Space Models with Regime Switching_ Classical and Gibbs Sampling Approaches with Applications.pdf:PDF},
  groups     = {SSM},
  keywords   = {regime switching, gibbs-sampling, posterior distributions, likelihood function},
  langid     = {english},
  shorttitle = {State-Space Models with Regime Switching},
  url        = {https://ideas.repec.org/b/mtp/titles/0262112388.html},
  urldate    = {2022-10-26},
}

@Article{castroalvarez2022a,
  author     = {Castro-Alvarez, Sebastian and Tendeiro, Jorge N. and de Jonge, Peter and Meijer, Rob R. and Bringmann, Laura F.},
  journal    = {Structural Equation Modeling: A Multidisciplinary Journal},
  title      = {Mixed-effects trait-state-occasion model: Studying the psychometric properties and the person–situation interactions of psychological dynamics},
  year       = {2022},
  issn       = {1070-5511},
  month      = may,
  number     = {3},
  pages      = {438--451},
  volume     = {29},
  abstract   = {The trait-state-occasion model ({TSO}) is a popular model within the latent state-trait theory ({LST}). The {TSO} allows distinguishing the trait and the state components of the psychological constructs measured in longitudinal data, while also taking into account the carry-over effects between consecutive measurements. In the present study, we extend a multilevel version of the {TSO} model to allow for the combination of fixed and random situations, namely the mixed-effects {TSO} ({ME}-{TSO}). Hence, the {ME}-{TSO} model is a measurement model suitable to analyze intensive longitudinal data that allows studying the psychometric properties of the indicators per individual, the heterogeneity of psychological dynamics, and the person–situation interaction effects. We showcase how to use the model by analyzing the items of positive affect activation of the crowdsourcing study {HowNutsAreTheDutch} ({HoeGekisNL}).},
  doi        = {10.1080/10705511.2021.1961587},
  file       = {:castroalvarez2022a - Mixed Effects Trait State Occasion Model_ Studying the Psychometric Properties and the Person–situation Interactions of Psychological Dynamics.pdf:PDF},
  groups     = {SSM, Longitudinal data, Reliability},
  keywords   = {Trait-state-occasion model, dynamic structural equation modeling, person–situation interaction},
  priority   = {prio3},
  publisher  = {Routledge},
  readstatus = {skimmed},
  shorttitle = {Mixed-Effects Trait-State-Occasion Model},
  url        = {https://doi.org/10.1080/10705511.2021.1961587},
  urldate    = {2022-10-27},
}

@Article{schoenbrodt2022,
  author       = {Schönbrodt, Felix D. and Zygar-Hoffmann, Caroline and Nestler, Steffen and Pusch, Sebastian and Hagemeyer, Birk},
  journal      = {Behavior Research Methods},
  title        = {Measuring motivational relationship processes in experience sampling: A reliability model for moments, days, and persons nested in couples},
  year         = {2022},
  issn         = {1554-3528},
  month        = aug,
  number       = {4},
  pages        = {1869--1888},
  volume       = {54},
  abstract     = {The investigation of within-person process models, often done in experience sampling designs, requires a reliable assessment of within-person change. In this paper, we focus on dyadic intensive longitudinal designs where both partners of a couple are assessed multiple times each day across several days. We introduce a statistical model for variance decomposition based on generalizability theory (extending P. E. Shrout \& S. P. Lane, 2012), which can estimate the relative proportion of variability on four hierarchical levels: moments within a day, days, persons, and couples. Based on these variance estimates, four reliability coefficients are derived: between-couples, between-persons, within-persons/between-days, and within-persons/between-moments. We apply the model to two dyadic intensive experience sampling studies (n1 = 130 persons, 5 surveys each day for 14 days, ≥ 7508 unique surveys; n2 = 508 persons, 5 surveys each day for 28 days, ≥ 47764 unique surveys). Five different scales in the domain of motivational processes and relationship quality were assessed with 2 to 5 items: State relationship satisfaction, communal motivation, and agentic motivation; the latter consists of two subscales, namely power and independence motivation. Largest variance components were on the level of persons, moments, couples, and days, where within-day variance was generally larger than between-day variance. Reliabilities ranged from .32 to .76 (couple level), .93 to .98 (person level), .61 to .88 (day level), and .28 to .72 (moment level). Scale intercorrelations reveal differential structures between and within persons, which has consequences for theory building and statistical modeling.},
  doi          = {10.3758/s13428-021-01701-7},
  file         = {:schoenbrodt2022 - Measuring Motivational Relationship Processes in Experience Sampling_ a Reliability Model for Moments Days and Persons Nested in Couples.pdf:PDF},
  groups       = {Longitudinal data, Multilevel, Reliability},
  keywords     = {Relationship, Motivation, Intensive longitudinal designs, Change reliability, Experience sampling, Ambulatory assessment},
  langid       = {english},
  ranking      = {rank5},
  readstatus   = {read},
  shortjournal = {Behav Res},
  shorttitle   = {Measuring motivational relationship processes in experience sampling},
  url          = {https://doi.org/10.3758/s13428-021-01701-7},
  urldate      = {2022-10-27},
}

 
@Book{mehl2013,
  author   = {Mehl, Matthias R. and Conner, Tamlin S.},
  title    = {Handbook of research methods for studying daily life},
  year     = {2013},
  isbn     = {9781462513055},
  month    = oct,
  abstract = {Bringing together leading authorities, this unique handbook reviews the breadth of current approaches for studying how people think, feel, and behave in everyday environments, rather than in the laboratory. The volume thoroughly describes experience sampling methods, diary methods, physiological measures, and other self-report and non-self-report tools that allow for repeated, real-time measurement in natural settings.},
  file     = {:mehl2013 - Handbook of Research Methods for Studying Daily Life.pdf:PDF},
  groups   = {ILD},
  langid   = {american},
  url      = {https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055/contents},
  urldate  = {2022-10-31},
}

@InCollection{shrout2012,
  author     = {Shrout, Patrick E. and Lane, Sean P.},
  booktitle  = {Handbook of research methods for studying daily life},
  publisher  = {The Guilford Press},
  title      = {Psychometrics},
  year       = {2012},
  address    = {New York, {NY}, {US}},
  chapter    = {17},
  editor     = {Mehl, Matthias R. and Conner, Tamlin S.},
  pages      = {302--320},
  abstract   = {A basic provision of good research design is that measures should have good psychometric properties; that is, the measures should reflect the constructs of scientific interest and have minimal measurement error. Psychometric texts (e.g., Crocker \& Algina, 1986; Embretson \& Reise, 2000) instruct researchers on how to achieve these goals for single time point individual-difference measures, but rarely is attention paid to the psychometrics of intensive repeated measures, such as those obtained in diary studies. In this chapter we aim to provide guidelines and techniques for this special measurement context. Our focus is on the classic psychometric concepts of reliability and validity. We say that a measure is reliable when repeated applications of the measurement procedure produce the same numerical value. We say that a measure has validity if there is evidence that scores from the measurement procedure display empirical patterns that are consistent with the theoretical construct of interest. Reliability is necessary but not sufficient for validity (e.g., Shrout \& Lane, in press). It is possible to obtain a highly reliable measure that is not at all related to the construct for which it is named. We begin the chapter with a brief review of some of the special characteristics of diary studies that affect measurement quality. We then consider issues of reliability for diary data, noting that different definitions of reliability need to be used for between-person comparisons and within-person questions. Following our practical description of how to estimate reliability in diary studies, we consider issues of documenting the validity of diary measures. Throughout the chapter we illustrate the points with a numerical example based on an actual diary study. ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
  file       = {:shrout2012 - Psychometrics.pdf:PDF},
  groups     = {ILD, Psychometrics, GT, Multilevel, Reliability},
  keywords   = {Experimentation, Psychometrics, Test Reliability, Test Validity, Experimental Design, Journal Writing, Research Psychologists},
  readstatus = {read},
  url        = {https://psycnet.apa.org/record/2012-05165-017},
}

@Article{shrout2012b,
  author     = {Shrout, Patrick E. and Lane, Sean P.},
  title      = {Reliability},
  year       = {2012},
  pages      = {643--660},
  booktitle  = {{APA} handbook of research methods in psychology, Vol 1: Foundations, planning, measures, and psychometrics.},
  doi        = {10.1037/13619-034},
  file       = {:shrout2012b - Reliability.pdf:PDF},
  groups     = {Psychometrics, Overview, Reliability},
  publisher  = {American Psychological Association},
  readstatus = {read},
}

@Book{shavelson1991,
  author     = {Shavelson, Richard J. and Webb, Noreen M.},
  publisher  = {SAGE Publications, Inc},
  title      = {Generalizability theory: A primer},
  year       = {1991},
  file       = {:shavelson1991 - Generalizability Theory_ a Primer.pdf:PDF},
  groups     = {Psychometrics, GT, Reliability},
  readstatus = {skimmed},
}

 
@Article{cranford2006,
  author       = {Cranford, James A. and Shrout, Patrick E. and Iida, Masumi and Rafaeli, Eshkol and Yip, Tiffany and Bolger, Niall},
  journal      = {Personality \& social psychology bulletin},
  title        = {A procedure for evaluating sensitivity to within-person change: Can mood measures in diary studies detect change reliably?},
  year         = {2006},
  issn         = {0146-1672},
  month        = jul,
  number       = {7},
  pages        = {917--929},
  volume       = {32},
  abstract     = {The recent growth in diary and experience sampling research has increased research attention on how people change over time in natural settings. Often however, the measures in these studies were originally developed for studying between-person differences, and their sensitivity to within-person changes is usually unknown. Using a Generalizability Theory framework, the authors illustrate a procedure for developing reliable measures of change using a version of the Profile of Mood States ({POMS}; ) shortened for diary studies. Analyzing two data sets, one composed of 35 daily reports from 68 persons experiencing a stressful examination and another composed of daily reports from 164 persons over a typical 28-day period, we demonstrate that three-item measures of anxious mood, depressed mood, anger, fatigue, and vigor have appropriate reliability to detect within-person change processes.},
  doi          = {10.1177/0146167206287721},
  file         = {:cranford2006 - A Procedure for Evaluating Sensitivity to within Person Change_ Can Mood Measures in Diary Studies Detect Change Reliably_.pdf:PDF},
  groups       = {Psychometrics, Affect, GT, Multilevel, Reliability},
  pmcid        = {PMC2414486},
  pmid         = {16738025},
  readstatus   = {read},
  shortjournal = {Pers Soc Psychol Bull},
  shorttitle   = {A Procedure for Evaluating Sensitivity to Within-Person Change},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2414486/},
  urldate      = {2022-10-31},
}

@Article{castroalvarez2022,
  author     = {Castro-Alvarez, Sebastian and Tendeiro, Jorge N. and Meijer, Rob R. and Bringmann, Laura F.},
  journal    = {Psychological Methods},
  title      = {Using structural equation modeling to study traits and states in intensive longitudinal data},
  year       = {2022},
  issn       = {1939-1463},
  pages      = {17--43},
  volume     = {27},
  abstract   = {Traditionally, researchers have used time series and multilevel models to analyze intensive longitudinal data. However, these models do not directly address traits and states which conceptualize the stability and variability implicit in longitudinal research, and they do not explicitly take into account measurement error. An alternative to overcome these drawbacks is to consider structural equation models (state-trait {SEMs}) for longitudinal data that represent traits and states as latent variables. Most of these models are encompassed in the latent state-trait ({LST}) theory. These state-trait {SEMs} can be problematic when the number of measurement occasions increases. As they require the data to be in wide format, these models quickly become overparameterized and lead to nonconvergence issues. For these reasons, multilevel versions of state-trait {SEMs} have been proposed, which require the data in long format. To study how suitable state-trait {SEMs} are for intensive longitudinal data, we carried out a simulation study. We compared the traditional single level to the multilevel version of three state-trait {SEMs}. The selected models were the multistate-singletrait ({MSST}) model, the common and unique trait-state ({CUTS}) model, and the trait–state-occasion ({TSO}) model. Furthermore, we also included an empirical application. Our results indicated that the {TSO} model performed best in both the simulated and the empirical data. To conclude, we highlight the usefulness of state-trait {SEMs} to study the psychometric properties of the questionnaires used in intensive longitudinal data. Yet, these models still have multiple limitations, some of which might be overcome by extending them to more general frameworks. ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
  address    = {{US}},
  doi        = {10.1037/met0000393},
  file       = {:castroalvarez2022 - Using Structural Equation Modeling to Study Traits and States in Intensive Longitudinal Data.pdf:PDF},
  groups     = {SSM, Longitudinal data, Reliability},
  keywords   = {Error of Measurement, Measurement, Models, Simulation, Structural Equation Modeling, Longitudinal Studies, Psychometrics, Questionnaires, Time Series},
  priority   = {prio3},
  publisher  = {American Psychological Association},
  readstatus = {skimmed},
}

 
@Article{vangeneugden2005,
  author     = {Vangeneugden, Tony and Laenen, Annouschka and Geys, Helena and Renard, Didier and Molenberghs, Geert},
  journal    = {Biometrics},
  title      = {Applying concepts of generalizability theory on clinical trial data to investigate sources of variation and their impact on reliability},
  year       = {2005},
  issn       = {1541-0420},
  number     = {1},
  pages      = {295--304},
  volume     = {61},
  abstract   = {This work aims at applying concepts of generalizability theory to data resulting from clinical trials. The focus is to study the sources of variance and their impact on the reliability and generalizability of a psychiatric measurement scale. The goal is to identify, measure, and thereby potentially find strategies to reduce the influence of these sources on the measurement in question for future trials. This approach was originally devised by Cronbach and his associates and is known as generalizability theory. This work shows how full modeling power in mixed models can be used to study generalizability using data from five double-blind randomized clinical trials, comparing the effects of risperidone to conventional antipsychotic agents for the treatment of chronic schizophrenia.},
  doi        = {10.1111/j.0006-341X.2005.031040.x},
  file       = {:Bibliography/vangeneugden2005 - Applying Concepts of Generalizability Theory on Clinical Trial Data to Investigate Sources of Variation and Their Impact on Reliability.pdf:PDF},
  groups     = {Cor, Reliability},
  keywords   = {D-study, Generalizability, G-study, Reliability, Variance components},
  langid     = {english},
  ranking    = {rank5},
  readstatus = {read},
  url        = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2005.031040.x},
  urldate    = {2022-11-17},
}

 
@InCollection{strube2000,
  author     = {Strube, Michael J.},
  booktitle  = {Reading and understanding {MORE} multivariate statistics},
  publisher  = {American Psychological Association},
  title      = {Reliability and generalizability theory},
  year       = {2000},
  address    = {Washington, {DC}, {US}},
  editor     = {Grimm, Laurence G. and Yarnold, Paul R.},
  isbn       = {9781557986986},
  pages      = {23--66},
  abstract   = {In this chapter, I describe more formally the importance of reliability to science and show how scientists determine the reliability of their observations. I begin by describing more specifically the basic task that scientists try to accomplish in their work and show how reliability is crucial to accomplishing that task. Then I give a formal definition of reliability as it is typically used in scientific measurement—the so-called classical theory. An important extension of the classical view, called generalizability theory, is the focus of most of this chapter. Generalizability theory allows precise estimation of reliability, and it is a general-purpose approach to investigating broad questions about the consistency or dependability of measurement. Generalizability theory, as typically used, is a multivariable procedure. It makes use of repeated measures analysis of variance ({ANOVA}) in which multiple measures or observations are taken on the same units of measure (typically people, but the units could be any observable objects). Generalizability theory has a multivariate extension that is discussed. ({PsycINFO} Database Record (c) 2019 {APA}, all rights reserved)},
  file       = {:strube2000 - Reliability and Generalizability Theory.pdf:PDF},
  groups     = {GT, Reliability},
  keywords   = {Consistency (Measurement), Multivariate Analysis, Statistical Reliability, Theories, Analysis of Variance, Experimentation, Social Sciences},
  readstatus = {skimmed},
}

@Book{bolger2013,
  author    = {Bolger, Niall and Laurenceau, Jean-Philippe},
  publisher = {The Guilford Press},
  title     = {Intensive longitudinal methods: An introduction to diary and experience sampling research},
  year      = {2013},
  isbn      = {146250678X},
  series    = {Methodology in the Social Sciences},
  file      = {:bolger2013 - Intensive Longitudinal Methods_ an Introduction to Diary and Experience Sampling Research.pdf:PDF},
  groups    = {ILD},
}

@InCollection{walls2006a,
  author     = {Walls, Theodore A. and Jung, Hyekyung and Schwartz, Joseph E.},
  booktitle  = {Models for intensive longitudinal data},
  publisher  = {Oxford University Press},
  title      = {Multilevel models for intensive longitudinal data},
  year       = {2006},
  editor     = {Walls, Theodore A. and Schafer, Joseph L.},
  pages      = {3--37},
  file       = {:walls2006a - Multilevel Models for Intensive Longitudinal Data.pdf:PDF},
  groups     = {ILD},
  ranking    = {rank4},
  readstatus = {read},
}

@InCollection{ho2006,
  author     = {Ho, Moon-Ho Ringo and Shumway, Robert and Ombao, Hernando},
  booktitle  = {Models for intensive longitudinal data},
  publisher  = {Oxford University Press},
  title      = {The state-space approach to modeling dynamic processes},
  year       = {2006},
  editor     = {Walls, Theodore A. and Schafer, Joseph L.},
  pages      = {148--175},
  file       = {:ho2006 - The State Space Approach to Modeling Dynamic Processes.pdf:PDF},
  groups     = {ILD, SSM},
  ranking    = {rank4},
  readstatus = {read},
}

 
@Article{icaza1999,
  author   = {Icaza, Gloria and Jones, Richard},
  journal  = {Journal of Time Series Analysis},
  title    = {A state-space {EM} algorithm for longitudinal data},
  year     = {1999},
  issn     = {1467-9892},
  number   = {5},
  pages    = {537--550},
  volume   = {20},
  abstract = {An exact {EM} algorithm is developed for Gaussian longitudinal mixed models in state-space form. These models include between-subject random effects as well as within-subject serial correlation and possibly observational error. Data for each subject may be equally spaced with missing observations, or unequally spaced with different observation times for different subjects. The method uses the Kalman filter and smoothing algorithm to obtain the conditional expectations of the unobserved data given the observations used in the E step of the {EM} algorithm. Maximum likelihood estimates of the parameters are obtained wtihout the need to use nonlinear optimization routines. Using simulations, the method is shown to give identical results to maximum likelihood methods that use nonlinear optimization.},
  doi      = {10.1111/1467-9892.00155},
  file     = {:icaza1999 - A State Space EM Algorithm for Longitudinal Data.pdf:PDF},
  groups   = {SSM},
  keywords = {Kalman filter, longitudinal data, serial correlation, state-space smoother, unequally spaced observations.},
  langid   = {english},
  priority = {prio3},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9892.00155},
  urldate  = {2023-01-03},
}

 
@Book{triantafyllopoulos2021,
  author     = {Triantafyllopoulos, Kostas},
  publisher  = {Springer Nature},
  title      = {Bayesian inference of state space models: kalman filtering and beyond},
  year       = {2021},
  isbn       = {9783030761240},
  month      = nov,
  note       = {Google-Books-{ID}: {mGxOEAAAQBAJ}},
  abstract   = {Bayesian Inference of State Space Models: Kalman Filtering and Beyond offers a comprehensive introduction to Bayesian estimation and forecasting for state space models. The celebrated Kalman filter, with its numerous extensions, takes centre stage in the book. Univariate and multivariate models, linear Gaussian, non-linear and non-Gaussian models are discussed with applications to signal processing, environmetrics, economics and systems engineering. Over the past years there has been a growing literature on Bayesian inference of state space models, focusing on multivariate models as well as on non-linear and non-Gaussian models. The availability of time series data in many fields of science and industry on the one hand, and the development of low-cost computational capabilities on the other, have resulted in a wealth of statistical methods aimed at parameter estimation and forecasting. This book brings together many of these methods, presenting an accessible and comprehensive introduction to state space models. A number of data sets from different disciplines are used to illustrate the methods and show how they are applied in practice. The R package {BTSA}, created for the book, includes many of the algorithms and examples presented. The book is essentially self-contained and includes a chapter summarising the prerequisites in undergraduate linear algebra, probability and statistics. An up-to-date and complete account of state space methods, illustrated by real-life data sets and R code, this textbook will appeal to a wide range of students and scientists, notably in the disciplines of statistics, systems engineering, signal processing, data science, finance and econometrics. With numerous exercises in each chapter, and prerequisite knowledge conveniently recalled, it is suitable for upper undergraduate and graduate courses.},
  file       = {:triantafyllopoulos2021 - Bayesian Inference of State Space Models_ Kalman Filtering and beyond.pdf:PDF},
  groups     = {SSM},
  keywords   = {Mathematics / Probability \& Statistics / General, Science / System Theory, Mathematics / Probability \& Statistics / Stochastic Processes, Language Arts \& Disciplines / Library \& Information Science / General},
  langid     = {english},
  pagetotal  = {503},
  priority   = {prio1},
  shorttitle = {Bayesian Inference of State Space Models},
}

 
@Article{molenberghs2007,
  author     = {Molenberghs, Geert and Laenen, Annouschka and Vangeneugden, Tony},
  journal    = {Journal of Biopharmaceutical Statistics},
  title      = {Estimating reliability and generalizability from hierarchical biomedical data},
  year       = {2007},
  issn       = {1054-3406},
  month      = jul,
  number     = {4},
  pages      = {595--627},
  volume     = {17},
  abstract   = {It is shown how hierarchical biomedical data, such as coming from longitudinal clinical trials, meta-analyses, or a combination of both, can be used to provide evidence for quantitative strength of reliability, agreement, generalizability, and related measures that derive from association concepts. When responses are of a continuous, Gaussian type, the linear mixed model is shown to be a versatile framework. At the same time, the framework is embedded in the generalized linear mixed models, such that non-Gaussian, e.g., binary, outcomes can be studied as well. Similarities and, above all, important differences are studied. All developments are exemplified using clinical studies in schizophrenia, with focus on the endpoints Clinician's Global Impression ({CGI}) or Positive and Negative Syndrome Scale ({PANSS}).},
  doi        = {10.1080/10543400701329448},
  file       = {:molenberghs2007 - Estimating Reliability and Generalizability from Hierarchical Biomedical Data.pdf:PDF},
  groups     = {Cor, Longitudinal data, Reliability},
  keywords   = {Generalizability, Generalized linear mixed model, Linear mixed model, Longitudinal data, Psychiatry, Rating scale, Reliability, Repeated measurements, Schizophrenia, ▪},
  pmid       = {17613644},
  publisher  = {Taylor \& Francis},
  ranking    = {rank5},
  readstatus = {read},
  url        = {https://doi.org/10.1080/10543400701329448},
  urldate    = {2023-01-06},
}

 
@Article{laenen2009,
  author   = {Laenen, Annouschka and Alonso, Ariel and Molenberghs, Geert and Vangeneugden, Tony},
  journal  = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  title    = {A family of measures to evaluate scale reliability in a longitudinal setting},
  year     = {2009},
  issn     = {1467-985X},
  number   = {1},
  pages    = {237--253},
  volume   = {172},
  abstract = {Summary. The concept of reliability denotes one of the most important psychometric properties of a measurement scale. Reliability refers to the capacity of the scale to discriminate between subjects in a given population. In classical test theory, it is often estimated by using the intraclass correlation coefficient based on two replicate measurements. However, the modelling framework that is used in this theory is often too narrow when applied in practical situations. Generalizability theory has extended reliability theory to a much broader framework but is confronted with some limitations when applied in a longitudinal setting. We explore how the definition of reliability can be generalized to a setting where subjects are measured repeatedly over time. On the basis of four defining properties for the concept of reliability, we propose a family of reliability measures which circumscribes the area in which reliability measures should be sought. It is shown how different members assess different aspects of the problem and that the reliability of the instrument can depend on the way that it is used. The methodology is motivated by and illustrated on data from a clinical study on schizophrenia. On the basis of this study, we estimate and compare the reliabilities of two different rating scales to evaluate the severity of the disorder.},
  doi      = {10.1111/j.1467-985X.2008.00554.x},
  file     = {:laenen2009 - A Family of Measures to Evaluate Scale Reliability in a Longitudinal Setting.pdf:PDF},
  groups   = {Cor, Longitudinal data, Reliability},
  keywords = {Clinical trials, Hierarchical models, Longitudinal data, Rating scales, Reliability},
  langid   = {english},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-985X.2008.00554.x},
  urldate  = {2023-01-06},
}

 
@Article{bartko1966,
  author       = {Bartko, John J.},
  journal      = {Psychological Reports},
  title        = {The intraclass correlation coefficient as a measure of reliability},
  year         = {1966},
  issn         = {0033-2941},
  month        = aug,
  number       = {1},
  pages        = {3--11},
  volume       = {19},
  abstract     = {A procedure for estimating the reliability of sets of ratings in terms of the intraclass correlation coefficient is discussed. The procedure is based upon the analysis of variance and the estimation of variance components. For the one-way classification the intraclass correlation coefficient defined as the ratio of variances can be interpreted as a correlation coefficient. Caution, however, is urged in the application of the definition to a two-way model, i.e., one in which between-rater variance is removed. It is maintained that the frequent use of the standard definition of the one-way intraclass correlation coefficient applied to the two-way classification is not a proper procedure if in fact the coefficient is to be interpreted as a correlation coefficient. Definitions for reliability obtained from the two-way models are given which can legitimately be considered correlation coefficients.},
  doi          = {10.2466/pr0.1966.19.1.3},
  file         = {:bartko1966 - The Intraclass Correlation Coefficient As a Measure of Reliability.pdf:PDF},
  groups       = {Cor, ICC, Reliability},
  publisher    = {{SAGE} Publications Inc},
  ranking      = {rank4},
  readstatus   = {read},
  shortjournal = {Psychol Rep},
  url          = {https://doi.org/10.2466/pr0.1966.19.1.3},
  urldate      = {2023-01-10},
}

 
@Article{cronbach1963,
  author     = {Cronbach, Lee J. and Rajaratnam, Nageswari and Gleser, Goldine C.},
  journal    = {British Journal of Statistical Psychology},
  title      = {Theory of generalizability: A liberalization of reliability theory},
  year       = {1963},
  issn       = {2044-8317},
  number     = {2},
  pages      = {137--163},
  volume     = {16},
  abstract   = {“Reliability theory” is reinterpreted as a theory regarding the adequac with which one can generalize from one observation to a universe of observations. If the observation is randomly sampled from the universe—whether or not the universe consists of equivalent observations—the intraclass correlation provides an approximate lower bound to the expected value of the desired coefficient of generalizability.},
  doi        = {10.1111/j.2044-8317.1963.tb00206.x},
  file       = {:cronbach1963 - Theory of Generalizability_ a Liberalization of Reliability Theory.pdf:PDF},
  groups     = {Cor, GT, Overview, Reliability},
  langid     = {english},
  shorttitle = {Theory of Generalizability},
  url        = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.1963.tb00206.x},
  urldate    = {2023-01-10},
}

 
@Article{cronbach1972,
  author    = {Cronbach, Lee Joseph},
  journal   = {Theory of generalizability for scores and profiles},
  title     = {The dependability of behavioral measurements},
  year      = {1972},
  pages     = {1--33},
  file      = {:cronbach1972 - The Dependability of Behavioral Measurements.pdf:PDF},
  groups    = {GT, Reliability},
  publisher = {Johon Wilely \& Sons},
}

 
@Article{vangeneugden2004,
  author       = {Vangeneugden, Tony and Laenen, Annouschka and Geys, Helena and Renard, Didier and Molenberghs, Geert},
  journal      = {Controlled Clinical Trials},
  title        = {Applying linear mixed models to estimate reliability in clinical trial data with repeated measurements},
  year         = {2004},
  issn         = {0197-2456},
  month        = feb,
  number       = {1},
  pages        = {13--30},
  volume       = {25},
  abstract     = {Repeated measures are exploited to study reliability in the context of psychiatric health sciences. It is shown how test–retest reliability can be derived using linear mixed models when the scale is continuous or quasi-continuous. The advantage of this approach is that the full modeling power of mixed models can be used. Repeated measures with a different mean structure can be used to usefully study reliability, correction for covariate effects is possible, and a complicated variance–covariance structure between measurements is allowed. In case the variance structure reduces to a random intercept (compound symmetry), classical methods are recovered. With more complex variance structures (e.g., including random slopes of time and/or serial correlation), time-dependent reliability functions are obtained. The methodology is motivated by and applied to data from five double-blind randomized clinical trials comparing the effects of risperidone to conventional antipsychotic agents for the treatment of chronic schizophrenia. Model assumptions are investigated through residual plots and by investigating the effect of influential observations.},
  doi          = {10.1016/j.cct.2003.08.009},
  file         = {:vangeneugden2004 - Applying Linear Mixed Models to Estimate Reliability in Clinical Trial Data with Repeated Measurements.pdf:PDF},
  groups       = {Cor, Reliability},
  keywords     = {Reliability, Linear mixed model, Repeated measurements, Psychiatry, Rating scale},
  langid       = {english},
  readstatus   = {skimmed},
  shortjournal = {Controlled Clinical Trials},
  url          = {https://www.sciencedirect.com/science/article/pii/S0197245603001338},
  urldate      = {2023-01-11},
}

 
@Article{laenen2007,
  author       = {Laenen, Annouschka and Alonso, Ariel and Molenberghs, Geert},
  journal      = {Psychometrika},
  title        = {A measure for the reliability of a rating scale based on longitudinal clinical trial data},
  year         = {2007},
  issn         = {1860-0980},
  month        = jun,
  number       = {3},
  pages        = {443},
  volume       = {72},
  abstract     = {A new measure for reliability of a rating scale is introduced, based on the classical definition of reliability, as the ratio of the true score variance and the total variance. Clinical trial data can be employed to estimate the reliability of the scale in use, whenever repeated measurements are taken. The reliability is estimated from the covariance parameters obtained from a linear mixed model. The method provides a single number to express the reliability of the scale, but allows for the study of the reliability’s time evolution. The method is illustrated using a case study in schizophrenia.},
  doi          = {10.1007/s11336-007-9002-7},
  file         = {:laenen2007 - A Measure for the Reliability of a Rating Scale Based on Longitudinal Clinical Trial Data.pdf:PDF},
  groups       = {Cor, Longitudinal data, Reliability},
  keywords     = {reliability, linear mixed model, longitudinal data, psychiatry, rating scale},
  langid       = {english},
  shortjournal = {Psychometrika},
  url          = {https://doi.org/10.1007/s11336-007-9002-7},
  urldate      = {2023-01-11},
}

 
@Article{laenen2009a,
  author       = {Laenen, Annouschka and Alonso, Ariel and Molenberghs, Geert and Vangeneugden, Tony},
  journal      = {Psychometrika},
  title        = {Reliability of a longitudinal sequence of scale ratings},
  year         = {2009},
  issn         = {1860-0980},
  month        = sep,
  number       = {1},
  pages        = {49},
  volume       = {74},
  abstract     = {Reliability captures the influence of error on a measurement and, in the classical setting, is defined as one minus the ratio of the error variance to the total variance. Laenen, Alonso, and Molenberghs (Psychometrika 73:443–448, 2007) proposed an axiomatic definition of reliability and introduced the {RTcoefficient}, a measure of reliability extending the classical approach to a more general longitudinal scenario. The {RTcoefficient} can be interpreted as the average reliability over different time points and can also be calculated for each time point separately. In this paper, we introduce a new and complementary measure, the so-called {RΛ}, which implies a new way of thinking about reliability. In a longitudinal context, each measurement brings additional knowledge and leads to more reliable information. The {RΛcaptures} this intuitive idea and expresses the reliability of the entire longitudinal sequence, in contrast to an average or occasion-specific measure. We study the measure’s properties using both theoretical arguments and simulations, establish its connections with previous proposals, and elucidate its performance in a real case study.},
  doi          = {10.1007/s11336-008-9079-7},
  file         = {:laenen2009a - Reliability of a Longitudinal Sequence of Scale Ratings.pdf:PDF},
  groups       = {Cor, Longitudinal data, Reliability},
  keywords     = {reliability, linear mixed model, longitudinal data, psychiatry, rating scale},
  langid       = {english},
  shortjournal = {Psychometrika},
  url          = {https://doi.org/10.1007/s11336-008-9079-7},
  urldate      = {2023-01-06},
}

 
@Article{vangeneugden2010,
  author    = {Vangeneugden, Tony and Molenberghs, Geert and Laenen, Annouschka and Geys, Helena and Beunckens, Caroline and Sotto, Cristina},
  journal   = {Communications in Statistics - Theory and Methods},
  title     = {Marginal correlation in longitudinal binary data based on generalized linear mixed models},
  year      = {2010},
  issn      = {0361-0926},
  month     = sep,
  number    = {19},
  pages     = {3540--3557},
  volume    = {39},
  abstract  = {This work aims at investigating marginal correlation within and between longitudinal data sequences. Useful and intuitive approximate expressions are derived based on generalized linear mixed models. Data from four double-blind randomized clinical trials are used to estimate the intra-class coefficient of reliability for a binary response. Additionally, the correlation between such a binary response and a continuous response is derived to evaluate the criterion validity of the binary response variable and the established continuous response variable.},
  doi       = {10.1080/03610920903249568},
  file      = {:vangeneugden2010 - Marginal Correlation in Longitudinal Binary Data Based on Generalized Linear Mixed Models.pdf:PDF},
  groups    = {Cor, Reliability},
  keywords  = {Binary data, Intraclass correlation, Random effects, Reliability, Variances, 62Fxx, 92Cxx},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/03610920903249568},
  urldate   = {2023-01-12},
}

@Book{fisher1954,
  author    = {Fisher, Ronald Aylmer},
  publisher = {Oliver and Boyd},
  title     = {Statistical methods for research workers},
  year      = {1954},
  edition   = {12th},
  isbn      = {978-0-05-002170-5},
  file      = {:fisher1954 - Statistical Methods for Research Workers.pdf:PDF},
  groups    = {ICC, Experimental Design},
}

@Book{streiner2015,
  author    = {Streiner, David L. and Norman, Geoffrey R. and Cairney, John},
  publisher = {Oxford University Press},
  title     = {Health measurement scales},
  year      = {2015},
  month     = {jan},
  doi       = {10.1093/med/9780199685219.001.0001},
  file      = {:streiner2015 - Health Measurement Scales.pdf:PDF},
  groups    = {Overview},
}

 
@Article{shavelson1989,
  author     = {Shavelson, Richard J. and Webb, Noreen M. and Rowley, Glenn L.},
  journal    = {American Psychologist},
  title      = {Generalizability theory.},
  year       = {1989},
  number     = {6},
  pages      = {922},
  volume     = {44},
  file       = {:shavelson1989 - Generalizability Theory..pdf:PDF},
  groups     = {GT, Multilevel},
  publisher  = {American Psychological Association},
  readstatus = {skimmed},
}

 
@Article{koo2016,
  author       = {Koo, Terry K. and Li, Mae Y.},
  journal      = {Journal of Chiropractic Medicine},
  title        = {A guideline of selecting and reporting intraclass correlation coefficients for reliability research},
  year         = {2016},
  issn         = {1556-3707},
  month        = jun,
  number       = {2},
  pages        = {155--163},
  volume       = {15},
  abstract     = {Objective Intraclass correlation coefficient ({ICC}) is a widely used reliability index in test-retest, intrarater, and interrater reliability analyses. This article introduces the basic concept of {ICC} in the content of reliability analysis.  Discussion for Researchers There are 10 forms of {ICCs}. Because each form involves distinct assumptions in their calculation and will lead to different interpretations, researchers should explicitly specify the {ICC} form they used in their calculation. A thorough review of the research design is needed in selecting the appropriate form of {ICC} to evaluate reliability. The best practice of reporting {ICC} should include software information, “model,” “type,” and “definition” selections.  Discussion for Readers When coming across an article that includes {ICC}, readers should first check whether information about the {ICC} form has been reported and if an appropriate {ICC} form was used. Based on the 95\% confident interval of the {ICC} estimate, values less than 0.5, between 0.5 and 0.75, between 0.75 and 0.9, and greater than 0.90 are indicative of poor, moderate, good, and excellent reliability, respectively.  Conclusion This article provides a practical guideline for clinical researchers to choose the correct form of {ICC} and suggests the best practice of reporting {ICC} parameters in scientific publications. This article also gives readers an appreciation for what to look for when coming across {ICC} while reading an article.},
  doi          = {10.1016/j.jcm.2016.02.012},
  file         = {:koo2016 - A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research.pdf:PDF},
  groups       = {Reliability, ICC},
  pmcid        = {PMC4913118},
  pmid         = {27330520},
  shortjournal = {J Chiropr Med},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4913118/},
  urldate      = {2023-02-09},
}

 
@Article{demetrashvili2016,
  author       = {Demetrashvili, Nino and Wit, Ernst C. and van den Heuvel, Edwin R.},
  journal      = {Statistical Methods in Medical Research},
  title        = {Confidence intervals for intraclass correlation coefficients in variance components models},
  year         = {2016},
  issn         = {0962-2802},
  month        = oct,
  number       = {5},
  pages        = {2359--2376},
  volume       = {25},
  abstract     = {Confidence intervals for intraclass correlation coefficients in agreement studies with continuous outcomes are model-specific and no generic approach exists. This paper provides two generic approaches for intraclass correlation coefficients of the form ?q=1Qσq2/(?q=1Qσq2+?p=Q+1Pσp2). The first approach uses Satterthwaite?s approximation and an F-distribution. The second approach uses the first and second moments of the intraclass correlation coefficient estimate in combination with a Beta distribution. Both approaches are based on the restricted maximum likelihood estimates for the variance components involved. Simulation studies are conducted to examine the coverage probabilities of the confidence intervals for agreement studies with a mix of small sample sizes. Two different three-way variance components models and balanced and unbalanced one-way random effects models are investigated. The proposed approaches are compared with other approaches developed for these specific models. The approach based on the F-distribution provides acceptable coverage probabilities, but the approach based on the Beta distribution results in accurate coverages for most settings in both balanced and unbalanced designs. A real agreement study is provided to illustrate the approaches.},
  doi          = {10.1177/0962280214522787},
  file         = {:demetrashvili2016 - Confidence Intervals for Intraclass Correlation Coefficients in Variance Components Models.pdf:PDF},
  groups       = {ICC, Reliability, Overview, Probability},
  langid       = {english},
  publisher    = {{SAGE} Publications Ltd {STM}},
  shortjournal = {Stat Methods Med Res},
  url          = {https://doi.org/10.1177/0962280214522787},
  urldate      = {2022-12-20},
}

 
@Article{alonso2010,
  author   = {Alonso, Ariel and Laenen, Annouschka and Molenberghs, Geert and Geys, Helena and Vangeneugden, Tony},
  journal  = {Biometrics},
  title    = {A unified approach to multi-item reliability},
  year     = {2010},
  issn     = {1541-0420},
  number   = {4},
  pages    = {1061--1068},
  volume   = {66},
  abstract = {The reliability of multi-item scales has received a lot of attention in the psychometric literature, where a myriad of measures like the Cronbach's α or the Spearman–Brown formula have been proposed. Most of these measures, however, are based on very restrictive models that apply only to unidimensional instruments. In this article, we introduce two measures to quantify the reliability of multi-item scales based on a more general model. We show that they capture two different aspects of the reliability problem and satisfy a minimum set of intuitive properties. The relevance and complementary value of the measures is studied and earlier approaches are placed in a broader theoretical framework. Finally, we apply them to investigate the reliability of the Positive and Negative Syndrome Scale, a rating scale for the assessment of the severity of schizophrenia.},
  doi      = {10.1111/j.1541-0420.2009.01373.x},
  file     = {:alonso2010 - A Unified Approach to Multi Item Reliability.pdf:PDF},
  groups   = {Cor, Reliability, Probability, ICC},
  keywords = {Factor analysis, Multi-item rating scales, Reliability},
  langid   = {english},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2009.01373.x},
  urldate  = {2023-01-06},
}

 
@Article{rajaratnam1960,
  author       = {Rajaratnam, Nageswari},
  journal      = {Psychometrika},
  title        = {Reliability formulas for independent decision data when reliability data are matched},
  year         = {1960},
  issn         = {1860-0980},
  month        = sep,
  number       = {3},
  pages        = {261--271},
  volume       = {25},
  abstract     = {A distinction is made between reliability data and decision data. Each of these sets of data may be matched or independent, depending on whether the same instruments (tests, judges, etc.) are applied to every individual in the group or the instruments to be applied to each individual are selected independently for him. Reliability formulas are developed (for both single observations and for composites ofk observations) for the case where reliability data are matched but decision data are independent. Formulas previously reported in the literature are inappropriate for this case.},
  doi          = {10.1007/BF02289730},
  file         = {:rajaratnam1960 - Reliability Formulas for Independent Decision Data When Reliability Data Are Matched.pdf:PDF},
  groups       = {ICC, Probability},
  keywords     = {Public Policy, Statistical Theory, Reliability Data, Single Observation, Independent Decision},
  langid       = {english},
  shortjournal = {Psychometrika},
  url          = {https://doi.org/10.1007/BF02289730},
  urldate      = {2023-02-13},
}

 
@InCollection{barnhart2018,
  author    = {Barnhart, Huiman X.},
  booktitle = {Wiley {StatsRef}: Statistics Reference Online},
  publisher = {John Wiley \& Sons, Ltd},
  title     = {A review on assessing agreement},
  year      = {2018},
  isbn      = {9781118445112},
  pages     = {1--30},
  abstract  = {Measurements serve as the basis for evaluation in almost all scientific disciplines, especially in physical sciences, medical studies, and health care. Issues related to reliable and accurate measurement have evolved over many decades. Requiring a measurement to be identical to the truth is sometimes impractical or impossible either because (i) the truth is simply not available or is measured with some error or (ii) some tolerable error is acceptable. Concepts of agreement, including reproducibility or reliability, are often used to determine whether the measurements can be used or not for evaluation. There has been substantial statistical literature in the last several decades on assessing agreement. This article provides a critical and comprehensive review on agreement concepts and their corresponding agreement indices developed for assessing agreement among measurements made on the same subject or experimental unit. The emphasis is on the intuitive understanding of concepts and on insights into both controversies and appropriate applications for continuous and categorical data. Four examples with either continuous or categorical measurements are used for illustration and discussion.},
  doi       = {10.1002/9781118445112.stat01671.pub2},
  file      = {:barnhart2018 - A Review on Assessing Agreement.pdf:PDF},
  groups    = {Overview, Reliability},
  keywords  = {agreement, repeatability, reproducibility, reliability, test–retest reliability, intraobserver agreement, interobserver agreement, measurement error, method comparison},
  langid    = {english},
  priority  = {prio1},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat01671.pub2},
  urldate   = {2023-01-11},
}

 
@Article{bartko1974,
  author     = {Bartko, John J.},
  journal    = {Psychological Reports},
  title      = {Corrective note to: "The intraclass correlation coefficient as a measure of reliability."},
  year       = {1974},
  issn       = {1558-691X},
  pages      = {418--418},
  volume     = {34},
  abstract   = {Presents corrected equations for the author's previous paper (see record 1966-11636-001) which suggested a procedure for estimating the reliability of sets of ratings in terms of intraclass correlation coefficients. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
  address    = {{US}},
  doi        = {10.2466/pr0.1974.34.2.418},
  file       = {:bartko1974 - Corrective Note To_ _The Intraclass Correlation Coefficient As a Measure of Reliability._.pdf:PDF},
  groups     = {ICC},
  keywords   = {Rating Scales, Statistical Analysis, Statistical Correlation, Statistical Reliability},
  publisher  = {Psychological Reports},
  ranking    = {rank4},
  readstatus = {read},
  shorttitle = {Corrective note to},
}

 
@Book{lord1968,
  author    = {Lord, F.M. and Novick, M.R. and Birnbaum, Allan},
  publisher = {Addison-Wesley},
  title     = {Statistical theories of mental test scores},
  year      = {1968},
  address   = {Oxford, England},
  series    = {Statistical theories of mental test scores},
  abstract  = {A comprehensive theory of mental testing, covering such topics as statistical foundations, classical theory, weak true score models, validity, latent trait models, and strong true score theory.  Harvard Book List (edited) 1971 \#115 ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
  groups    = {CTT},
  ranking   = {rank5},
}

 
@Article{barnhart2007,
  author     = {Barnhart, Huiman X. and Haber, Michael J. and Lin, Lawrence I.},
  journal    = {Journal of Biopharmaceutical Statistics},
  title      = {An overview on assessing agreement with continuous measurements},
  year       = {2007},
  issn       = {1054-3406},
  month      = jul,
  number     = {4},
  pages      = {529--569},
  volume     = {17},
  abstract   = {Reliable and accurate measurements serve as the basis for evaluation in many scientific disciplines. Issues related to reliable and accurate measurement have evolved over many decades, dating back to the nineteenth century and the pioneering work of Galton (1886), Pearson (1896 1899 1901), and Fisher (1925). Requiring a new measurement to be identical to the truth is often impractical, either because (1) we are willing to accept a measurement up to some tolerable (or acceptable) error, or (2) the truth is simply not available to us, either because it is not measurable or is only measurable with some degree of error. To deal with issues related to both (1) and (2), a number of concepts, methods, and theories have been developed in various disciplines. Some of these concepts have been used across disciplines, while others have been limited to a particular field but may have potential uses in other disciplines. In this paper, we elucidate and contrast fundamental concepts employed in different disciplines and unite these concepts into one common theme: assessing closeness (agreement) of observations. We focus on assessing agreement with continuous measurements and classify different statistical approaches as (1) descriptive tools; (2) unscaled summary indices based on absolute differences of measurements; and (3) scaled summary indices attaining values between –1 and 1 for various data structures, and for cases with and without a reference. We also identify gaps that require further research and discuss future directions in assessing agreement.},
  doi        = {10.1080/10543400701376480},
  file       = {:barnhart2007 - An Overview on Assessing Agreement with Continuous Measurements.pdf:PDF},
  groups     = {Overview, Reliability, ICC, GT, Cor, CCC},
  keywords   = {Accuracy, Agreement, Coefficient of individual agreement, Concordance correlation coefficient, Coverage probability, Generalizability, Intraclass correlation coefficient, Limits of agreement, Method comparison, Precision, Reliability, Repeatability, Reproducibility, Tolerance interval, Total deviation index, Validity},
  pmid       = {17613641},
  priority   = {prio1},
  publisher  = {Taylor \& Francis},
  ranking    = {rank5},
  readstatus = {skimmed},
  url        = {https://doi.org/10.1080/10543400701376480},
  urldate    = {2023-01-11},
}

 
@Book{mcdonald1999,
  author     = {{McDonald}, Roderick P.},
  publisher  = {Lawrence Erlbaum Associates Publishers},
  title      = {Test theory: A unified treatment},
  year       = {1999},
  address    = {Mahwah, {NJ}, {US}},
  isbn       = {9780805830750},
  series     = {Test theory: A unified treatment},
  abstract   = {This book is an outcome of {McDonald}'s experience in teaching a laboratory course on test theory in a university department of psychology. The object of such a course on test theory is to introduce students to the main quantitative concepts, methods, and computational techniques needed for the development, evaluation, and application of tests in the behavioral/social sciences, including educational tests. The implicit unifying principle throughout this book is a general nonlinear common factor model, which includes item response models as special cases, and includes also the (linear) common factor model as an approximation. The account of the field in this text is developed from that unifying perspective, while giving appropriate coverage of the conventional topics. This book is intended primarily for students of psychology, including educational psychology, and any other fields of social science where tests are constructed and used. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
  file       = {:mcdonald1999 - Test Theory_ a Unified Treatment.pdf:PDF},
  groups     = {CTT},
  keywords   = {Statistical Tests, Theories},
  shorttitle = {Test theory},
}

 
@Article{barnhart2002,
  author       = {Barnhart, Huiman X. and Haber, Michael and Song, Jingli},
  journal      = {Biometrics},
  title        = {Overall concordance correlation coefficient for evaluating agreement among multiple observers},
  year         = {2002},
  issn         = {0006-341X},
  month        = dec,
  number       = {4},
  pages        = {1020--1027},
  volume       = {58},
  abstract     = {Accurate and precise measurement is an important component of any proper study design. As elaborated by Lin (1989, Biometrics 45, 255-268), the concordance correlation coefficient ({CCC}) is more appropriate than other indices for measuring agreement when the variable of interest is continuous. However, this agreement index is defined in the context of comparing two fixed observers. In order to use multiple observers in a study involving large numbers of subjects, there is a need to assess agreement among these multiple observers. In this article, we present an overall {CCC} ({OCCC}) in terms of the interobserver variability for assessing agreement among multiple fixed observers. The {OCCC} turns out to be equivalent to the generalized {CCC} (King and Chinchilli, 2001, Statistics in Medicine 20, 2131-2147; Lin, 1989; Lin, 2000, Biometrics 56, 324-325) when the squared distance function is used. We evaluated the {OCCC} through generalized estimating equations (Barnhart and Williamson, 2001, Biometrics 57, 931-940) and U-statistics (King and Chinchilli, 2001) for inference. This article offers the following important points. First, it addresses the precision and accuracy indices as components of the {OCCC}. Second, it clarifies that the {OCCC} is the weighted average of all pairwise {CCCs}. Third, it is intuitively defined in terms of interobserver variability. Fourth, the inference approaches of {GEE} and the U-statistics are compared via simulations for small samples. Fifth, we illustrate the use of the {OCCC} by two medical examples with the {GEE}, U-statistics, and bootstrap approaches.},
  doi          = {10.1111/j.0006-341x.2002.01020.x},
  file         = {:barnhart2002 - Overall Concordance Correlation Coefficient for Evaluating Agreement among Multiple Observers.pdf:PDF},
  groups       = {CCC},
  keywords     = {Adult, Bias, Blood Pressure Determination, Carotid Stenosis, Computer Simulation, Electronics, Medical, Humans, Magnetic Resonance Angiography, Observer Variation, Reproducibility of Results, Sphygmomanometers},
  pmid         = {12495158},
  priority     = {prio1},
  ranking      = {rank4},
  readstatus   = {skimmed},
  shortjournal = {Biometrics},
}

 
@Article{almehrizi2021,
  author    = {Almehrizi, Rashid S. and Emam, Mahmoud},
  journal   = {Communications in Statistics - Simulation and Computation},
  title     = {Asymptotic standard errors of intraclass correlation coefficients for two-way model},
  year      = {2021},
  issn      = {0361-0918},
  month     = apr,
  number    = {0},
  pages     = {1--27},
  volume    = {0},
  abstract  = {Intraclass correlation coefficients are estimated using appropriate analysis of variance models that are commonly used in behavioral measurement, biometric, and psychometric. The {ICCs} estimation accuracy is quantified by the degree of their sampling variability using the asymptotic standard errors or confidence intervals, which facilitates conducting hypothesis testing on {ICCs}. The article derived the asymptotic standard errors of absolute agreement {ICC} and relative consistency {ICC} for the two-way model. Monte Carlo simulations were performed for both normal data and nonnormal data under different conditions. Results supported that the proposed asymptotic standard errors for all {ICCs} were converging to the simulated true standard errors under different test conditions.},
  doi       = {10.1080/03610918.2021.1897624},
  file      = {:almehrizi2021 - Asymptotic Standard Errors of Intraclass Correlation Coefficients for Two Way Model.pdf:PDF},
  groups    = {ICC},
  keywords  = {Absolute agreement, Asymptotic standard error, Confidence interval, Intraclass correlation coefficient, Relative consistency},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/03610918.2021.1897624},
  urldate   = {2023-04-13},
}

 
@Article{brennan1977a,
  author     = {Brennan, Robert L. and Kane, Michael T.},
  journal    = {Journal of Educational Measurement},
  title      = {An index of dependability for mastery tests},
  year       = {1977},
  issn       = {0022-0655},
  number     = {3},
  pages      = {277--289},
  volume     = {14},
  abstract   = {In this paper we develop an index of dependability for mastery tests. We define a mastery test as a criterion-referenced or domain-referenced test with a single mastery cutting score, C. We assume that a given mastery test consists of a random sample of items from an infinite universe. We make only weak assumptions about the nature of the universe and no assumption about how C is defined. Using generalizability theory, our analysis leads to an index, M(C), which incorporates a definition of error (Δ) different from the usual definition of error (δ) in classical test theory. Δ differs from δ in that Δ takes into account the sampling of the main effect due to items. Also, the index M(C) entails the assumption of randomly parallel tests, rather than the stronger assumption of classically parallel tests.},
  file       = {:brennan1977a - An Index of Dependability for Mastery Tests.pdf:PDF},
  groups     = {GT},
  publisher  = {[National Council on Measurement in Education, Wiley]},
  ranking    = {rank4},
  readstatus = {read},
  url        = {https://www.jstor.org/stable/1434319},
  urldate    = {2023-04-14},
}

 
@Article{shavelson1981,
  author     = {Shavelson, Richard J. and Webb, Noreen M.},
  journal    = {British Journal of Mathematical and Statistical Psychology},
  title      = {Generalizability theory: 1973–1980},
  year       = {1981},
  issn       = {2044-8317},
  number     = {2},
  pages      = {133--166},
  volume     = {34},
  abstract   = {This paper reviews the developments in generalizability theory from 1973 to 1980. The first section presents a sketch of generalizability theory. The second section reviews theoretical contributions about (1) problems associated with estimating variance components, including sampling variability and negative estimates, (2) fixed facets, (3) criterion-referenced measurement, (4) symmetry, (5) multivariate generalizability, and (6) sampling in observational measurement. The final section presents an illustrative application of generalizability theory, including univariate and multivariate generalizability analyses of balanced and unbalanced designs, and Bayesian estimation of variance components.},
  doi        = {10.1111/j.2044-8317.1981.tb00625.x},
  file       = {:shavelson1981 - Generalizability Theory_ 1973–1980.pdf:PDF},
  groups     = {GT},
  langid     = {english},
  shorttitle = {Generalizability theory},
  url        = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.1981.tb00625.x},
  urldate    = {2023-04-19},
}

 
@Article{marcoulides1990,
  author       = {Marcoulides, George A.},
  journal      = {Psychological Reports},
  title        = {An alternative method for estimating variance components in generalizability theory},
  year         = {1990},
  issn         = {0033-2941},
  month        = apr,
  number       = {2},
  pages        = {379--386},
  volume       = {66},
  abstract     = {This study compares, using simulated data, two methods for estimating variance components in generalizability (G) studies. Traditionally variance components are estimated from an analysis of variance of sample data. The alternative method for estimating variance components is restricted maximum likelihood ({REML}). The results indicate that {REML} provides estimates for the components in the various designs that are closer to the true parameters than the estimates from analysis of variance.},
  doi          = {10.2466/pr0.1990.66.2.379},
  file         = {:marcoulides1990 - An Alternative Method for Estimating Variance Components in Generalizability Theory.pdf:PDF},
  groups       = {GT},
  langid       = {english},
  publisher    = {{SAGE} Publications Inc},
  shortjournal = {Psychol Rep},
  url          = {https://doi.org/10.2466/pr0.1990.66.2.379},
  urldate      = {2023-04-19},
}

 
@Article{hallgren2012,
  author       = {Hallgren, Kevin A.},
  journal      = {Tutorials in Quantitative Methods for Psychology},
  title        = {Computing inter-rater reliability for observational data: An overview and tutorial},
  year         = {2012},
  issn         = {1913-4126},
  month        = feb,
  number       = {1},
  pages        = {23--34},
  volume       = {8},
  doi          = {10.20982/tqmp.08.1.p023},
  file         = {:hallgren2012 - Computing Inter Rater Reliability for Observational Data_ an Overview and Tutorial.pdf:PDF},
  groups       = {Overview},
  shortjournal = {{TQMP}},
  shorttitle   = {Computing Inter-Rater Reliability for Observational Data},
  url          = {http://www.tqmp.org/RegularArticles/vol08-1/p023},
  urldate      = {2023-04-24},
}

 
@Article{vanbelle2012,
  author   = {Vanbelle, Sophie and Mutsvari, Timothy and Declerck, Dominique and Lesaffre, Emmanuel},
  journal  = {Statistics in Medicine},
  title    = {Hierarchical modeling of agreement},
  year     = {2012},
  issn     = {1097-0258},
  number   = {28},
  pages    = {3667--3680},
  volume   = {31},
  abstract = {Kappa-like agreement indexes are often used to assess the agreement among examiners on a categorical scale. They have the particularity of correcting the level of agreement for the effect of chance. In the present paper, we first define two agreement indexes belonging to this family in a hierarchical context. In particular, we consider the cases of a random and fixed set of examiners. Then, we develop a method to evaluate the influence of factors on these indexes. Agreement indexes are directly related to a set of covariates through a hierarchical model. We obtain the posterior distribution of the model parameters in a Bayesian framework. We apply the proposed approach on dental data and compare it with the generalized estimating equations approach. Copyright © 2012 John Wiley \& Sons, Ltd.},
  doi      = {10.1002/sim.5424},
  file     = {:vanbelle2012 - Hierarchical Modeling of Agreement.pdf:PDF},
  groups   = {Multilevel},
  keywords = {Cohen's kappa, intraclass, reliability, multilevel, Markov chain Monte Carlo, nested, rater},
  langid   = {english},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5424},
  urldate  = {2023-04-24},
}

 
@Article{zygar2018,
  author       = {Zygar, Caroline and Hagemeyer, Birk and Pusch, Sebastian and Schönbrodt, Felix D.},
  journal      = {European Journal of Personality},
  title        = {From motive dispositions to states to outcomes: An intensive experience sampling study on communal motivational dynamics in couples},
  year         = {2018},
  issn         = {0890-2070},
  month        = may,
  number       = {3},
  pages        = {306--324},
  volume       = {32},
  abstract     = {Embedded in a theoretically founded process model (termed Dynamics of Motive Satisfaction, ?{DynaMoS}?), the present study examined the links between the implicit dispositional communion motive, everyday motivational dynamics, and relationship outcomes in couples. Within?subject processes are proposed to explain between?subject associations of dispositional motives and relationship satisfaction. For an empirical test of the model, data on the dispositional partner?related need for communion and global relationship satisfaction were obtained from 152 individuals in heterosexual relationships. In an extensive experience sampling spanning 2 weeks, a subsample of 130 individuals answered questions about their current motivational states, mood, state relationship satisfaction, and experiences with their partner five times a day. The results were largely consistent with the {DynaMoS} model: (1) individuals with a strong dispositional implicit communion motive reported more often to be in a communal motivational state; (2) communally motivated individuals were more likely to engage in subsequent instrumental behaviour; and (3) relationship experiences that potentially satisfy communion motivation led to more positive relationship outcomes when individuals were motivated before compared with when they were not. It is discussed how these results and the experience sampling method can foster our understanding of how dispositional characteristics translate into everyday processes and shape relationship outcomes. Copyright ? 2018 European Association of Personality Psychology},
  doi          = {10.1002/per.2145},
  file         = {:zygar2018 - From Motive Dispositions to States to Outcomes_ an Intensive Experience Sampling Study on Communal Motivational Dynamics in Couples.pdf:PDF},
  groups       = {Multilevel},
  langid       = {english},
  publisher    = {{SAGE} Publications Ltd},
  shortjournal = {Eur J Pers},
  shorttitle   = {From Motive Dispositions to States to Outcomes},
  url          = {https://doi.org/10.1002/per.2145},
  urldate      = {2023-04-26},
}

 
@Article{zee2020,
  author     = {Zee, Marjolein and Rudasill, Kathleen Moritz and Roorda, Debora L.},
  journal    = {The Elementary School Journal},
  title      = {{“Draw Me a Picture”}: Student-teacher relationship drawings by children displaying externalizing, internalizing, or prosocial behavior},
  year       = {2020},
  issn       = {0013-5984},
  month      = jun,
  number     = {4},
  pages      = {636--666},
  volume     = {120},
  abstract   = {This study explored the role of students’ externalizing, internalizing, and prosocial behavior and classroom climate in their mental representations of student-teacher relationships. In total, 266 third to sixth graders and 35 teachers participated. Teachers completed questionnaires about students’ social-emotional behavior and student-teacher relationships. Relationship perceptions were aggregated to form a classroom climate measure. Students made drawings of themselves with the teacher, which were scored by independent coders on 8 dimensions. Multilevel models indicated that children with externalizing behavior depicted more tension/anger, bizarreness/dissociation, and emotional distance/isolation, and less pride/happiness in their drawings. Internalizing behavior was not associated with their mental relationship representations. Children with prosocial behavior depicted more creativity/vitality and less role reversal and global pathology than less prosocial counterparts. Classroom climate did not moderate linkages between child behavior and mental representations. These findings suggest that overt, rather than covert, behaviors play a role in students’ mental relationship representations.},
  doi        = {10.1086/708661},
  file       = {:zee2020 - “Draw Me a Picture”_ Student Teacher Relationship Drawings by Children Displaying Externalizing, Internalizing, or Prosocial Behavior.pdf:PDF},
  groups     = {Multilevel},
  publisher  = {The University of Chicago Press},
  shorttitle = {“Draw Me a Picture”},
  url        = {https://www.journals.uchicago.edu/doi/10.1086/708661},
  urldate    = {2023-04-26},
}

 
@Article{liljequist2019,
  author       = {Liljequist, David and Elfving, Britt and Roaldsen, Kirsti Skavberg},
  journal      = {{PLOS} {ONE}},
  title        = {Intraclass correlation – a discussion and demonstration of basic features},
  year         = {2019},
  issn         = {1932-6203},
  month        = jul,
  number       = {7},
  pages        = {e0219854},
  volume       = {14},
  abstract     = {A re-analysis of intraclass correlation ({ICC}) theory is presented together with Monte Carlo simulations of {ICC} probability distributions. A partly revised and simplified theory of the single-score {ICC} is obtained, together with an alternative and simple recipe for its use in reliability studies. Our main, practical conclusion is that in the analysis of a reliability study it is neither necessary nor convenient to start from an initial choice of a specified statistical model. Rather, one may impartially use all three single-score {ICC} formulas. A near equality of the three {ICC} values indicates the absence of bias (systematic error), in which case the classical (one-way random) {ICC} may be used. A consistency {ICC} larger than absolute agreement {ICC} indicates the presence of non-negligible bias; if so, classical {ICC} is invalid and misleading. An F-test may be used to confirm whether biases are present. From the resulting model (without or with bias) variances and confidence intervals may then be calculated. In presence of bias, both absolute agreement {ICC} and consistency {ICC} should be reported, since they give different and complementary information about the reliability of the method. A clinical example with data from the literature is given.},
  doi          = {10.1371/journal.pone.0219854},
  file         = {:liljequist2019 - Intraclass Correlation – a Discussion and Demonstration of Basic Features.pdf:PDF;:liljequist2019 - S1.pdf:PDF;:liljequist2019 - S2.pdf:PDF;:liljequist2019 - S3.pdf:PDF;:pone.0219854.s003.pdf:PDF},
  groups       = {ICC},
  keywords     = {Normal distribution, Monte Carlo method, Probability distribution, Statistical models, Simulation and modeling, Analysis of variance, Experimental design, Measurement},
  langid       = {english},
  priority     = {prio1},
  publisher    = {Public Library of Science},
  ranking      = {rank5},
  readstatus   = {skimmed},
  shortjournal = {{PLOS} {ONE}},
  url          = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0219854},
  urldate      = {2023-05-01},
}

 
@Article{carrasco2003,
  author       = {Carrasco, Josep L. and Jover, Lluís},
  journal      = {Biometrics},
  title        = {Estimating the generalized concordance correlation coefficient through variance components},
  year         = {2003},
  issn         = {0006-341X},
  month        = dec,
  number       = {4},
  pages        = {849--858},
  volume       = {59},
  abstract     = {The intraclass correlation coefficient ({ICC}) and the concordance correlation coefficient ({CCC}) are two of the most popular measures of agreement for variables measured on a continuous scale. Here, we demonstrate that {ICC} and {CCC} are the same measure of agreement estimated in two ways: by the variance components procedure and by the moment method. We propose estimating the {CCC} using variance components of a mixed effects model, instead of the common method of moments. With the variance components approach, the {CCC} can easily be extended to more than two observers, and adjusted using confounding covariates, by incorporating them in the mixed model. A simulation study is carried out to compare the variance components approach with the moment method. The importance of adjusting by confounding covariates is illustrated with a case example.},
  doi          = {10.1111/j.0006-341x.2003.00099.x},
  file         = {:carrasco2003 - Estimating the Generalized Concordance Correlation Coefficient through Variance Components.pdf:PDF},
  groups       = {CCC},
  keywords     = {Analysis of Variance, Biometry, Blood Pressure, Blood Pressure Determination, Humans, Models, Statistical, Reproducibility of Results, Research Design},
  pmid         = {14969463},
  shortjournal = {Biometrics},
}

 
@Article{mueller1994,
  author       = {Müller, R. and Büttner, P.},
  journal      = {Statistics in Medicine},
  title        = {A critical discussion of intraclass correlation coefficients},
  year         = {1994},
  issn         = {0277-6715},
  month        = dec,
  number       = {23},
  pages        = {2465--2476},
  volume       = {13},
  abstract     = {In general, intraclass correlation coefficients ({ICC}'s) are designed to assess consistency or conformity between two or more quantitative measurements. They are claimed to handle a wide range of problems, including questions of reliability, reproducibility and validity. It is shown that care must be taken in choosing a suitable {ICC} with respect to the underlying sampling theory. For this purpose a decision tree is developed. It may be used to choose a coefficient which is appropriate for a specific study setting. We demonstrate that different {ICC}'s may result in quite different values for the same data set, even under the same sampling theory. Other general limitations of {ICC}'s are also addressed. Potential alternatives are presented and discussed, and some recommendations are given for the use of an appropriate method.},
  doi          = {10.1002/sim.4780132310},
  file         = {:mueller1994 - A Critical Discussion of Intraclass Correlation Coefficients.pdf:PDF},
  groups       = {ICC},
  keywords     = {Analysis of Variance, Cardiac Output, Data Interpretation, Statistical, Decision Trees, Echocardiography, Doppler, Genetics, Humans, Models, Statistical, Observer Variation, Regression Analysis, Reproducibility of Results, Selection Bias, Statistics, Nonparametric},
  pmid         = {7701147},
  shortjournal = {Stat Med},
}

@Book{brennan2001,
  author     = {Brennan, Robert L.},
  publisher  = {Springer New York},
  title      = {Generalizability theory},
  year       = {2001},
  edition    = {1st},
  doi        = {10.1007/978-1-4757-3456-0},
  file       = {:brennan2001 - Generalizability Theory.pdf:PDF},
  groups     = {Psychometrics, GT, Reliability},
  priority   = {prio1},
  readstatus = {skimmed},
}

@Book{cardinet2009,
  author     = {Cardinet, Jean and Johnson, Sandra and Pini, Gianreto},
  publisher  = {Routledge},
  title      = {Applying generalizability theory using {EduG}},
  year       = {2009},
  address    = {New York},
  isbn       = {9780203866948},
  month      = nov,
  doi        = {10.4324/9780203866948},
  file       = {:cardinet2009 - Applying Generalizability Theory Using EduG.pdf:PDF},
  groups     = {GT, Reliability},
  readstatus = {skimmed},
}

 
@Article{geldhof2014,
  author     = {Geldhof, G. John and Preacher, Kristopher J. and Zyphur, Michael J.},
  journal    = {Psychological Methods},
  title      = {Reliability estimation in a multilevel confirmatory factor analysis framework},
  year       = {2014},
  issn       = {1939-1463},
  pages      = {72--91},
  volume     = {19},
  abstract   = {Scales with varying degrees of measurement reliability are often used in the context of multistage sampling, where variance exists at multiple levels of analysis (e.g., individual and group). Because methodological guidance on assessing and reporting reliability at multiple levels of analysis is currently lacking, we discuss the importance of examining level-specific reliability. We present a simulation study and an applied example showing different methods for estimating multilevel reliability using multilevel confirmatory factor analysis and provide supporting Mplus program code. We conclude that (a) single-level estimates will not reflect a scale’s actual reliability unless reliability is identical at each level of analysis, (b) 2-level alpha and composite reliability (omega) perform relatively well in most settings, (c) estimates of maximal reliability (H) were more biased when estimated using multilevel data than either alpha or omega, and (d) small cluster size can lead to overestimates of reliability at the between level of analysis. We also show that Monte Carlo confidence intervals and Bayesian credible intervals closely reflect the sampling distribution of reliability estimates under most conditions. We discuss the estimation of credible intervals using Mplus and provide R code for computing Monte Carlo confidence intervals. ({PsycINFO} Database Record (c) 2019 {APA}, all rights reserved)},
  address    = {{US}},
  doi        = {10.1037/a0032138},
  file       = {:geldhof2014 - Reliability Estimation in a Multilevel Confirmatory Factor Analysis Framework.pdf:PDF},
  groups     = {Multilevel, Reliability},
  keywords   = {Confirmatory Factor Analysis, Estimation, Factor Analysis, Statistical Reliability, Structural Equation Modeling, Confidence Limits (Statistics)},
  publisher  = {American Psychological Association},
  ranking    = {rank3},
  readstatus = {skimmed},
}

 
@Article{yang2022,
  author       = {Yang, Liu-Qin and Wang, Wei and Huang, Po-Hsien and Nguyen, Anthony},
  journal      = {Journal of Business and Psychology},
  title        = {Optimizing measurement reliability in within-person research: Guidelines for research design and {R} {Shiny} web application tools},
  year         = {2022},
  issn         = {1573-353X},
  month        = dec,
  number       = {6},
  pages        = {1141--1156},
  volume       = {37},
  abstract     = {Within-person research has become increasingly popular over recent years in the field of organizational studies for its unique theoretical and methodological advantages for studying dynamic intrapersonal processes (e.g., Dalal et al., Journal of Management 40:1396–1436, 2014; {McCormick} et al., Journal of Management 46:321–350, 2020). Despite the advancements, there remain serious challenges for many organizational researchers to fully appreciate and appropriately implement within-person research—more specifically, to correctly conceptualize and compute the within-person measurement reliability, as well as navigate key within-person research design factors (e.g., number of measurement occasions, T; number of participants, N; and scale length, I) to optimize within-person reliability. By conducting a comprehensive Monte Carlo simulation with 3240 data conditions, we offer a practical guideline table showing the expected within-person reliability as a function of key design factors. In addition, we provide three easy-to-use, free R Shiny web applications for within-person researchers to conveniently (a) compute expected within-person reliability based on their customized research design, (b) compute observed validity based on the expected reliability and hypothesized within-person validity, and (c) compute observed within-person (as well as between-person) reliability from collected within-person research datasets. We hope these much-needed evidence-based guidelines and practical tools will help enhance within-person research in organizational studies.},
  doi          = {10.1007/s10869-022-09803-5},
  file         = {:yang2022 - Optimizing Measurement Reliability in within Person Research_ Guidelines for Research Design and R Shiny Web Application Tools.pdf:PDF},
  groups       = {Multilevel, Reliability},
  keywords     = {Within-person research, Level-specific alpha, Reliability, R shiny web application, Validity},
  langid       = {english},
  shortjournal = {J Bus Psychol},
  shorttitle   = {Optimizing Measurement Reliability in Within-Person Research},
  url          = {https://doi.org/10.1007/s10869-022-09803-5},
  urldate      = {2023-01-17},
}

 
@Article{raudenbush1991,
  author    = {Raudenbush, Stephen W. and Rowan, Brian and Kang, Sang Jin},
  journal   = {Journal of Educational Statistics},
  title     = {A multilevel, multivariate model for studying school climate with estimation via the {EM} algorithm and application to {U.S.} high-school data},
  year      = {1991},
  issn      = {0362-9791},
  month     = dec,
  number    = {4},
  pages     = {295--330},
  volume    = {16},
  abstract  = {In many studies of school climate, researchers ask teachers a series of questions, and the responses to related questions are averaged or summed to create a scale score for each teacher on each dimension of climate under investigation. Researchers have disagreed, however, about the analysis of such data: Some have utilized the teacher as the analytic unit, and some have utilized the school as the unit. In this article, we propose a three-level, multivariate statistical modeling strategy that resolves the unit-of-analysis dilemma and unifies thinking about the analysis in such studies. A reanalysis of U. S. high-school data illustrates how to estimate and interpret: (a) the level of interteacher agreement on each climate dimension; (b) the internal consistency of measurement at the teacher and school levels; and (c) the correlations among “true” climate scores at each level. A linear model analysis utilized teacher control over school and classroom policy and teacher morale as bivariate latent outcomes to be predicted by school-level variables (e.g., sector, size, composition) and by teacher-level variables (e.g., education, race, sex, subject matter). Implications for conceptualization, design, analysis, and interpretation in future studies of school climate are considered.},
  doi       = {10.3102/10769986016004295},
  file      = {:raudenbush1991 - A Multilevel, Multivariate Model for Studying School Climate with Estimation Via the EM Algorithm and Application to U.S. High School Data.pdf:PDF},
  groups    = {Multilevel},
  langid    = {english},
  publisher = {American Educational Research Association},
  url       = {https://doi.org/10.3102/10769986016004295},
  urldate   = {2023-05-26},
}

@Article{bonito2012,
  author    = {Joseph A. Bonito and Erin K. Ruppel and Joann Keyton},
  journal   = {Small Group Research},
  title     = {Reliability estimates for multilevel designs in group research},
  year      = {2012},
  month     = {may},
  number    = {4},
  pages     = {443--467},
  volume    = {43},
  doi       = {10.1177/1046496412437614},
  file      = {:bonito2012 - Reliability Estimates for Multilevel Designs in Group Research.pdf:PDF},
  groups    = {Multilevel},
  publisher = {{SAGE} Publications},
}

 
@Article{novick1971,
  author       = {Novick, Melvin R. and Jackson, Paul H. and Thayer, Dorothy T.},
  journal      = {Psychometrika},
  title        = {Bayesian inference and the classical test theory model: Reliability and true scores},
  year         = {1971},
  issn         = {1860-0980},
  month        = sep,
  number       = {3},
  pages        = {261--288},
  volume       = {36},
  abstract     = {A general one-way analysis of variance components with unequal replication numbers is used to provide unbiased estimates of the true and error score variance of classical test theory. The inadequacy of the {ANOVA} theory is noted and the foundations for a Bayesian approach are detailed. The choice of prior distribution is discussed and a justification for the Tiao-Tan prior is found in the particular context of the “n-split” technique. The posterior distributions of reliability, error score variance, observed score variance and true score variance are presented with some extensions of the original work of Tiao and Tan. Special attention is given to simple approximations that are available in important cases and also to the problems that arise when the {ANOVA} estimate of true score variance is negative. Bayesian methods derived by Box and Tiao and by Lindley are studied numerically in relation to the problem of estimating true score. Each is found to be useful and the advantages and disadvantages of each are discussed and related to the classical test-theoretic methods. Finally, some general relationships between Bayesian inference and classical test theory are discussed.},
  doi          = {10.1007/BF02297848},
  file         = {:novick1971 - Bayesian Inference and the Classical Test Theory Model_ Reliability and True Scores.pdf:PDF},
  groups       = {CTT},
  keywords     = {Variance Component, Posterior Distribution, Prior Distribution, Bayesian Inference, Bayesian Approach},
  langid       = {english},
  shortjournal = {Psychometrika},
  shorttitle   = {Bayesian inference and the classical test theory model},
  url          = {https://doi.org/10.1007/BF02297848},
  urldate      = {2023-06-15},
}

 
@Article{novick1967,
  author       = {Novick, Melvin R. and Lewis, Charles},
  journal      = {Psychometrika},
  title        = {Coefficient alpha and the reliability of composite measurements},
  year         = {1967},
  issn         = {1860-0980},
  month        = mar,
  number       = {1},
  pages        = {1--13},
  volume       = {32},
  abstract     = {Following a general approach due to Guttman, coefficientα is rederived as a lower bound on the reliability of a test. A necessary and sufficient condition under which equality is attained in this inequality and hence thatα is equal to the reliability of the test is derived and shown to be closely related to the recent redefinition of the concept of parallel measurements due to Novick. This condition is then also shown to be closely related to the unit rank assumption originally adopted by Kuder and Richardson in the derivation of their formula 20. The assumption later adopted by Jackson and Ferguson and the one adopted by Gulliksen are shown to be related to the necessary and sufficient condition derived here. It is then pointed out that the statement that “coefficientα is equal to the mean of the split-half reliabilities” is true only under the restricted condition assumed by Cronbach in the body of his derivation of this result. Finally some limitations on the uses of any function ofα as a measure of internal consistency are noted.},
  doi          = {10.1007/BF02289400},
  file         = {:novick1967 - Coefficient Alpha and the Reliability of Composite Measurements.pdf:PDF},
  groups       = {CTT},
  keywords     = {Internal Consistency, Public Policy, Statistical Theory, Coefficient Alpha, Composite Measurement},
  langid       = {english},
  shortjournal = {Psychometrika},
  url          = {https://doi.org/10.1007/BF02289400},
  urldate      = {2023-06-15},
}

 
@InProceedings{hove2020,
  author     = {ten Hove, Debby and Jorgensen, Terrence D. and van der Ark, L. Andries},
  booktitle  = {Quantitative Psychology},
  title      = {Comparing hyperprior distributions to estimate variance components for interrater reliability coefficients},
  year       = {2020},
  address    = {Cham},
  editor     = {Wiberg, Marie and Molenaar, Dylan and González, Jorge and Böckenholt, Ulf and Kim, Jee-Seon},
  pages      = {79--93},
  publisher  = {Springer International Publishing},
  series     = {Springer Proceedings in Mathematics \& Statistics},
  abstract   = {Interrater reliability ({IRR}) is often estimated by intraclass correlation coefficients ({ICCs}). Using Markov chain Monte Carlo ({MCMC}) estimation of Bayesian hierarchical models to estimate {ICCs} has several benefits over traditional approaches such as analysis of variance or maximum likelihood estimation. However, estimation of {ICCs} with small sample sizes and variance parameters close to zero, which are typical conditions in studies for which the {IRR} should be estimated, remains problematic in this {MCMC} approach. The estimation of the variance components that are used to estimate {ICCs} can heavily depend on the hyperprior distributions specified for these random-effect parameters. In this study, we explore the effect of a uniform and half-t hyperprior distribution on bias, coverage, and efficiency of the random-effect parameters and {ICCs}. The results indicated that a half-t distribution outperforms a uniform distribution but that slightly increasing the number of raters in a study is more influential than the choice of hyperprior distributions. We discuss implications and directions for future research.},
  doi        = {10.1007/978-3-030-43469-4_7},
  file       = {:hove2020 - Comparing Hyperprior Distributions to Estimate Variance Components for Interrater Reliability Coefficients.pdf:PDF},
  groups     = {ICC, Reliability},
  isbn       = {9783030434694},
  keywords   = {Bayesian hierarchical modeling, Hyperprior distributions, Interrater reliability, Intraclass correlation coefficients, Markov chain Monte Carlo estimation, Random effects, Variance components},
  langid     = {english},
  ranking    = {rank3},
  readstatus = {read},
}

 
@Article{hove2022a,
  author     = {ten Hove, Debby and Jorgensen, Terrence D. and van der Ark, L. Andries},
  journal    = {Psychological Methods},
  title      = {Updated guidelines on selecting an intraclass correlation coefficient for interrater reliability, with applications to incomplete observational designs},
  year       = {2022},
  issn       = {1939-1463},
  abstract   = {Several intraclass correlation coefficients ({ICCs}) are available to assess the interrater reliability ({IRR}) of observational measurements. Selecting an {ICC} is complicated, and existing guidelines have three major limitations. First, they do not discuss incomplete designs, in which raters partially vary across subjects. Second, they provide no coherent perspective on the error variance in an {ICC}, clouding the choice between the available coefficients. Third, the distinction between fixed or random raters is often misunderstood. Based on generalizability theory ({GT}), we provide updated guidelines on selecting an {ICC} for {IRR}, which are applicable to both complete and incomplete observational designs. We challenge conventional wisdom about {ICCs} for {IRR} by claiming that raters should seldom (if ever) be considered fixed. Also, we clarify how to interpret {ICCs} in the case of unbalanced and incomplete designs. We explain four choices a researcher needs to make when selecting an {ICC} for {IRR}, and guide researchers through these choices by means of a flowchart, which we apply to three empirical examples from clinical and developmental domains. In the Discussion, we provide guidance in reporting, interpreting, and estimating {ICCs}, and propose future directions for research into the {ICCs} for {IRR}. ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
  address    = {{US}},
  doi        = {10.1037/met0000516},
  file       = {:hove2022a - Updated Guidelines on Selecting an Intraclass Correlation Coefficient for Interrater Reliability, with Applications to Incomplete Observational Designs.pdf:PDF},
  groups     = {ICC, GT, Overview, Reliability},
  keywords   = {Experimental Design, Interrater Reliability, Measurement, Observation Methods, Statistical Correlation, Theories},
  publisher  = {American Psychological Association},
  readstatus = {skimmed},
}

@InCollection{hove2018,
  author     = {Debby ten Hove and Terrence D. Jorgensen and L. Andries van der Ark},
  booktitle  = {Springer Proceedings in Mathematics & Statistics},
  publisher  = {Springer International Publishing},
  title      = {On the usefulness of interrater reliability coefficients},
  year       = {2018},
  pages      = {67--75},
  doi        = {10.1007/978-3-319-77249-3_6},
  file       = {:hove2018 - On the Usefulness of Interrater Reliability Coefficients.pdf:PDF},
  groups     = {Overview},
  ranking    = {rank3},
  readstatus = {read},
}

 
@Article{vanbelle2023,
  author    = {Vanbelle, Sophie and Lesaffre, Emmanuel},
  journal   = {Statistical Modelling},
  title     = {Modelling agreement for binary intensive longitudinal data},
  year      = {2023},
  issn      = {1471-082X},
  month     = apr,
  number    = {2},
  pages     = {127--150},
  volume    = {23},
  abstract  = {Devices that measure our physical, medical and mental condition have entered our daily life recently. Such devices measure our status in a continuous manner and can be useful in predicting future medical events or can guide us towards a healthier life. It is therefore important to establish that such devices record our behaviour in a reliable manner and measure what we believe they measure. In this article, we propose to measure the reliability and validity of a newly developed measuring device in time using a longitudinal model for sequential kappa statistics. We propose a Bayesian estimation procedure. The method is illustrated by a validation study of a new accelerometer in cardiopulmonary rehabilitation patients.},
  doi       = {10.1177/1471082X211034002},
  file      = {:vanbelle2023 - Modelling Agreement for Binary Intensive Longitudinal Data.pdf:PDF},
  groups    = {Longitudinal data, Kappa},
  langid    = {english},
  priority  = {prio1},
  publisher = {{SAGE} Publications India},
  url       = {https://doi.org/10.1177/1471082X211034002},
  urldate   = {2023-06-19},
}

 
@Article{lai2021,
  author     = {Lai, Mark H. C.},
  journal    = {Psychological Methods},
  title      = {Composite reliability of multilevel data: It’s about observed scores and construct meanings},
  year       = {2021},
  issn       = {1939-1463},
  number     = {1},
  pages      = {90--102},
  volume     = {26},
  abstract   = {This article shows how the concept of reliability of composite scores, as defined in classical test theory, can be extended to the context of multilevel modeling. In particular, it discusses the contributions and limitations of the various level-specific reliability indices proposed by Geldhof, Preacher, and Zyphur (2014), denoted as ω̃b and ω̃w (and also α̃b and α̃w). One major limitation of those indices is that they are quantities for latent, unobserved level-specific composite scores, and are not suitable for observed composites at different levels. As illustrated using simulated data in this article, ω̃b can drastically overestimate the true reliability of between-level composite scores (i.e., observed cluster means). Another limitation is that the development of those indices did not consider the recent conceptual development on construct meanings in multilevel modeling (Stapleton \& Johnson, 2019; Stapleton, Yang, \& Hancock, 2016). To address the second limitation, this article defines reliability indices (ω2l, ωb, ωw, α2l, αb, αw) for three types of multilevel observed composite scores measuring various multilevel constructs: individual, configural, shared, and within-cluster. The article also shows how researchers can obtain sample point and interval estimates using the derived formulas and the provided R and Mplus code. In addition, a large-scale national data set was used to illustrate the proposed methods for estimating reliability for the three types of multilevel composite scores, and practical recommendations on when different indices should be reported are provided. ({PsycInfo} Database Record (c) 2021 {APA}, all rights reserved)},
  address    = {{US}},
  doi        = {10.1037/met0000287},
  file       = {:lai2021 - Composite Reliability of Multilevel Data_ It’s about Observed Scores and Construct Meanings.pdf:PDF},
  groups     = {Multilevel},
  keywords   = {Classical Test Theory, Simulation, Statistical Reliability},
  publisher  = {American Psychological Association},
  readstatus = {skimmed},
  shorttitle = {Composite reliability of multilevel data},
}

 
@Article{alphen2022,
  author     = {van Alphen, Thijmen and Jak, Suzanne and Jansen in de Wal, Joost and Schuitema, Jaap and Peetsma, Thea},
  journal    = {Applied Measurement in Education},
  title      = {Determining reliability of daily measures: An illustration with data on teacher stress},
  year       = {2022},
  issn       = {0895-7347},
  month      = jan,
  number     = {1},
  pages      = {63--79},
  volume     = {35},
  abstract   = {Intensive longitudinal data is increasingly used to study state-like processes such as changes in daily stress. Measures aimed at collecting such data require the same level of scrutiny regarding scale reliability as traditional questionnaires. The most prevalent methods used to assess reliability of intensive longitudinal measures are based on the generalizability theory or a multilevel factor analytic approach. However, the application of recent improvements made for the factor analytic approach may not be readily applicable for all researchers. Therefore, this article illustrates a five-step approach for determining reliability of daily data, which is one type of intensive longitudinal data. First, we show how the proposed reliability equations are applied. Next, we illustrate how these equations are used as part of our five-step approach with empirical data, originating from a study investigating changes in daily stress of secondary school teachers. The results are a within-level (ωw), between-level (ωb) reliability score. Mplus syntax for these examples is included and discussed. As such, this paper anticipates on the need for comprehensive guides for the analysis of daily data.},
  doi        = {10.1080/08957347.2022.2034822},
  file       = {:alphen2022 - Determining Reliability of Daily Measures_ an Illustration with Data on Teacher Stress.pdf:PDF},
  groups     = {Multilevel, Longitudinal data},
  publisher  = {Routledge},
  shorttitle = {Determining Reliability of Daily Measures},
  url        = {https://doi.org/10.1080/08957347.2022.2034822},
  urldate    = {2023-06-27},
}

 
@Book{durbin2012,
  author     = {Durbin, James and Koopman, Siem Jan},
  publisher  = {OUP Oxford},
  title      = {Time series analysis by state space methods},
  year       = {2012},
  edition    = {2nd},
  isbn       = {9780191627194},
  month      = may,
  note       = {Google-Books-ID: lGyshsfkLrIC},
  abstract   = {This new edition updates Durbin \& Koopman's important text on the state space approach to time series analysis. The distinguishing feature of state space time series models is that observations are regarded as made up of distinct components such as trend, seasonal, regression elements and disturbance terms, each of which is modelled separately. The techniques that emerge from this approach are very flexible and are capable of handling a much wider range of problems than the main analytical system currently in use for time series analysis, the Box-Jenkins ARIMA system. Additions to this second edition include the filtering of nonlinear and non-Gaussian series. Part I of the book obtains the mean and variance of the state, of a variable intended to measure the effect of an interaction and of regression coefficients, in terms of the observations. Part II extends the treatment to nonlinear and non-normal models. For these, analytical solutions are not available so methods are based on simulation.},
  file       = {:durbin2012 - Time Series Analysis by State Space Methods.pdf:PDF},
  groups     = {SSM, Time series},
  keywords   = {Business \& Economics / Statistics, Mathematics / Probability \& Statistics / General, Mathematics / Applied},
  language   = {en},
  priority   = {prio1},
  ranking    = {rank5},
  readstatus = {skimmed},
}

 
@Article{guttman1945,
  author       = {Guttman, Louis},
  journal      = {Psychometrika},
  title        = {A basis for analyzing test-retest reliability},
  year         = {1945},
  issn         = {1860-0980},
  month        = dec,
  number       = {4},
  pages        = {255--282},
  volume       = {10},
  abstract     = {Three sources of variation in experimental results for a test are distinguished: trials, persons, and items. Unreliability is defined only in terms of variation over trials. This definition leads to a more complete analysis than does the conventional one; Spearman's contention is verified that the conventional approach—which was formulated by Yule—introduces unnecessary hypotheses. It is emphasized that at least two trials are necessary to estimate the reliability coefficient. This paper is devoted largely to developinglower bounds to the reliability coefficient that can be computed from but asingle trial; these avoid the experimental difficulties of making two independent trials. Six different lower bounds are established, appropriate for different situations. Some of the bounds are easier to compute than are conventional formulas, and all the bounds assume less than do conventional formulas. The terminology used is that of psychological and sociological testing, but the discussion actually provides a general analysis of the reliability of the sum ofn variables.},
  doi          = {10.1007/BF02288892},
  file         = {:guttman1945 - A Basis for Analyzing Test Retest Reliability.pdf:PDF},
  groups       = {CTT},
  keywords     = {Lower Bound, Public Policy, Statistical Theory, General Analysis, Conventional Approach},
  langid       = {english},
  shortjournal = {Psychometrika},
  url          = {https://doi.org/10.1007/BF02288892},
  urldate      = {2023-07-25},
}

 
@Article{novick1966,
  author       = {Novick, Melvin R.},
  journal      = {Journal of Mathematical Psychology},
  title        = {The axioms and principal results of classical test theory},
  year         = {1966},
  issn         = {0022-2496},
  month        = feb,
  number       = {1},
  pages        = {1--18},
  volume       = {3},
  abstract     = {Following an approach due to Guttman the axioms of the classical test theory model are shown to be derivable as constructions from a specified sampling rule and from the assumption that the observed score of an arbitrarily specified or randomly selected person may be considered as an observation of a random variable having finite and positive variance. Without further assumption the reliability of a test is defined. Parallel measurements are then independently defined, and the concept of replication is explicated. The derived axioms of the classical test theory model are then stated in a refined form of Woodbury's stochastic process notation, and the basic results of this model are derived. The assumptions of experimental independence, homogeneity of error distribution, and conditional independence are related to the classical model and to each other. Finally, a brief sketch of some stronger models assuming the independence of error and true scores or the existence of higher-order moments of error distributions or those making specific distributional assumptions is given.},
  doi          = {10.1016/0022-2496(66)90002-2},
  file         = {:novick1966 - The Axioms and Principal Results of Classical Test Theory.pdf:PDF},
  groups       = {CTT},
  langid       = {english},
  ranking      = {rank5},
  readstatus   = {skimmed},
  shortjournal = {Journal of Mathematical Psychology},
  url          = {https://www.sciencedirect.com/science/article/pii/0022249666900022},
  urldate      = {2023-06-15},
}

 
@Book{casella2002,
  author     = {Casella, George and Berger, Roger L.},
  publisher  = {Cengage Learning},
  title      = {Statistical inference},
  year       = {2002},
  edition    = {2nd},
  isbn       = {9780357753132},
  note       = {Google-Books-{ID}: {FAUVEAAAQBAJ}},
  abstract   = {This book builds theoretical statistics from the first principles of probability theory. Starting from the basics of probability, the authors develop the theory of statistical inference using techniques, definitions, and concepts that are statistical and are natural extensions and consequences of previous concepts. Intended for first-year graduate students, this book can be used for students majoring in statistics who have a solid mathematics background. It can also be used in a way that stresses the more practical uses of statistical theory, being more concerned with understanding basic statistical concepts and deriving reasonable statistical procedures for a variety of situations, and less concerned with formal optimality investigations.Important Notice: Media content referenced within the product description or the product text may not be available in the ebook version.},
  file       = {:casella2002 - Statistical Inference.pdf:PDF},
  groups     = {Statistics, ILD},
  keywords   = {Mathematics / Probability \& Statistics / General},
  langid     = {english},
  pagetotal  = {660},
  ranking    = {rank5},
  readstatus = {skimmed},
}

@Article{mcgraw1996,
  author     = {McGraw, Kenneth O. and Wong, S. P.},
  journal    = {Psychological Methods},
  title      = {Forming inferences about some intraclass correlation coefficients},
  year       = {1996},
  issn       = {1939-1463},
  number     = {1},
  pages      = {30--46},
  volume     = {1},
  abstract   = {AIthough intraclass correlation coefficients (lCCs) are commonIy used in behavioral measurement, pychometrics, and behavioral genetics, procodures available for forming inferences about ICC are not widely known. Following a review of the distinction between various forms of the ICC, this article presents procedures available for calculating confidence intervals and conducting tests on ICCs developed using data from one-way and two-way random and mixed-efFect analysis of variance models. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  address    = {US},
  doi        = {10.1037/1082-989X.1.1.30},
  file       = {:mcgraw1996 - Forming Inferences about Some Intraclass Correlation Coefficients.pdf:PDF},
  groups     = {ICC, Reliability, GT},
  keywords   = {Confidence Limits (Statistics), Statistical Correlation, Statistical Significance, Variability Measurement},
  publisher  = {American Psychological Association},
  ranking    = {rank5},
  readstatus = {read},
}

 
@Article{Xiao2023,
  author     = {Xiao, Yue and Wang, Pujue and Liu, Hongyun},
  journal    = {Psychological Methods},
  title      = {Assessing intra- and inter-individual reliabilities in intensive longitudinal studies: {A} two-level random dynamic model-based approach},
  year       = {2023},
  issn       = {1939-1463},
  pages      = {No Pagination Specified--No Pagination Specified},
  abstract   = {Intensive longitudinal studies are becoming increasingly popular because of their potential for studying the individual dynamics of psychological processes. However, measures used in such studies are quite susceptible to measurement error due to the short lengths and therefore their psychometric properties, such as reliability, are of great concern. Most existing approaches for assessing reliability are not appropriate for the intensive longitudinal data (ILD) because of the conflation of inter- and intra-individual variations or the difficulty in handling interindividual differences. In addition, measurement models are always relegated or omitted in the ILD modeling approaches. Therefore, in this article, we introduce a two-level random dynamic measurement (2RDM) model for ILD, which takes into account measurement models for key variables of interest. Then we discuss how to derive the within-person and between-person reliabilities for items and scales in the context of the 2RDM model. A small simulation study is presented to illustrate the implementation of the 2RDM model and reliability estimation. An empirical study is then provided to demonstrate the application of the proposed approach for multidimensional scales, in which we calculated the within- and between-person reliabilities for both items and subscales of a short version of the Perceived Stress Scale and found large individual differences in the within-person reliabilities. We conclude by discussing the advantages and considerations of the proposed approach in practice. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  address    = {US},
  doi        = {10.1037/met0000608},
  file       = {:Xiao2023 - Assessing Intra and Inter Individual Reliabilities in Intensive Longitudinal Studies_ a Two Level Random Dynamic Model Based Approach.pdf:PDF},
  groups     = {Multilevel, Longitudinal data},
  keywords   = {Longitudinal Studies, Simulation, Statistical Reliability, Test Reliability, Measurement Models},
  publisher  = {American Psychological Association},
  shorttitle = {Assessing intra- and inter-individual reliabilities in intensive longitudinal studies},
}

@Article{schuurman2019,
  author     = {Schuurman, No{\'{e}}mi K. and Hamaker, Ellen L.},
  journal    = {Psychological Methods},
  title      = {Measurement error and person-specific reliability in multilevel autoregressive modeling.},
  year       = {2019},
  month      = feb,
  number     = {1},
  pages      = {70--91},
  volume     = {24},
  doi        = {10.1037/met0000188},
  file       = {:schuurman2019 - Measurement Error and Person Specific Reliability in Multilevel Autoregressive Modeling..pdf:PDF},
  groups     = {MVAR, SSM, ILD, Multilevel, Longitudinal data, Reliability},
  publisher  = {American Psychological Association ({APA})},
  readstatus = {read},
}

 
@Article{hove2022,
  author     = {ten Hove, Debby and Jorgensen, Terrence D. and van der Ark, L. Andries},
  journal    = {Psychological Methods},
  title      = {Interrater reliability for multilevel data: A generalizability theory approach},
  year       = {2022},
  issn       = {1939-1463},
  month      = aug,
  number     = {4},
  pages      = {650--666},
  volume     = {27},
  abstract   = {Current interrater reliability ({IRR}) coefficients ignore the nested structure of multilevel observational data, resulting in biased estimates of both subject- and cluster-level {IRR}. We used generalizability theory to provide a conceptualization and estimation method for {IRR} of continuous multilevel observational data. We explain how generalizability theory decomposes the variance of multilevel observational data into subject-, cluster-, and rater-related components, which can be estimated using Markov chain Monte Carlo ({MCMC}) estimation. We explain how {IRR} coefficients for each level can be derived from these variance components, and how they can be estimated as intraclass correlation coefficients ({ICC}). We assessed the quality of {MCMC} point and interval estimates with a simulation study, and showed that small numbers of raters were the main source of bias and inefficiency of the {ICCs}. In a follow-up simulation, we showed that a planned missing data design can diminish most estimation difficulties in these conditions, yielding a useful approach to estimating multilevel interrater reliability for most social and behavioral research. We illustrated the method using data on student–teacher relationships. All software code and data used for this article is available on the Open Science Framework: https://osf.io/bwk5t/. ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
  address    = {{US}},
  doi        = {10.1037/met0000391},
  file       = {:hove2022 - Interrater Reliability for Multilevel Data_ a Generalizability Theory Approach.pdf:PDF},
  groups     = {ICC, Multilevel, Reliability},
  keywords   = {Estimation, Experimental Design, Interrater Reliability, Simulation, Bayesian Analysis, Markov Chains, Statistical Probability},
  publisher  = {American Psychological Association},
  ranking    = {rank5},
  readstatus = {read},
  shorttitle = {Interrater reliability for multilevel data},
}

@Book{lord2008,
  author     = {Lord, Frederic M. and Novick, Melvin R.},
  publisher  = {{IAP}},
  title      = {Statistical theories of mental test scores},
  year       = {2008},
  file       = {:lord2008 - Statistical Theories of Mental Test Scores.PDF:PDF},
  groups     = {Psychometrics, CTT, Reliability},
  ranking    = {rank5},
  readstatus = {skimmed},
}

 
@Article{jeon2009,
  author    = {Jeon, Min-Jeong and Lee, Guemin and Hwang, Jeong-Won and Kang, Sang-Jin},
  journal   = {Asia Pacific Education Review},
  title     = {Estimating reliability of school-level scores using multilevel and generalizability theory models},
  year      = {2009},
  pages     = {149--158},
  volume    = {10},
  doi       = {10.1007/s12564-009-9014-3},
  file      = {:jeon2009 - Estimating Reliability of School Level Scores Using Multilevel and Generalizability Theory Models.pdf:PDF},
  groups    = {Multilevel, GT},
  publisher = {Springer},
}

 
@Article{Chen2017,
  author     = {Chen, Gang and Taylor, Paul A. and Haller, Simone P. and Kircanski, Katharina and Stoddard, Joel and Pine, Daniel S. and Leibenluft, Ellen and Brotman, Melissa A. and Cox, Robert W.},
  journal    = {Human Brain Mapping},
  title      = {Intraclass correlation: {Improved} modeling approaches and applications for neuroimaging},
  year       = {2017},
  issn       = {1065-9471},
  month      = dec,
  number     = {3},
  pages      = {1187--1206},
  volume     = {39},
  abstract   = {Intraclass correlation (ICC) is a reliability metric that gauges similarity when, for example, entities are measured under similar, or even the same, well‐controlled conditions, which in MRI applications include runs/sessions, twins, parent/child, scanners, sites, and so on. The popular definitions and interpretations of ICC are usually framed statistically under the conventional ANOVA platform. Here, we provide a comprehensive overview of ICC analysis in its prior usage in neuroimaging, and we show that the standard ANOVA framework is often limited, rigid, and inflexible in modeling capabilities. These intrinsic limitations motivate several improvements. Specifically, we start with the conventional ICC model under the ANOVA platform, and extend it along two dimensions: first, fixing the failure in ICC estimation when negative values occur under degenerative circumstance, and second, incorporating precision information of effect estimates into the ICC model. These endeavors lead to four modeling strategies: linear mixed‐effects (LME), regularized mixed‐effects (RME), multilevel mixed‐effects (MME), and regularized multilevel mixed‐effects (RMME). Compared to ANOVA, each of these four models directly provides estimates for fixed effects and their statistical significances, in addition to the ICC estimate. These new modeling approaches can also accommodate missing data and fixed effects for confounding variables. More importantly, we show that the MME and RMME approaches offer more accurate characterization and decomposition among the variance components, leading to more robust ICC computation. Based on these theoretical considerations and model performance comparisons with a real experimental dataset, we offer the following general‐purpose recommendations. First, ICC estimation through MME or RMME is preferable when precision information (i.e., weights that more accurately allocate the variances in the data) is available for the effect estimate; when precision information is unavailable, ICC estimation through LME or the RME is the preferred option. Second, even though the absolute agreement version, ICC(2,1), is presently more popular in the field, the consistency version, ICC(3,1), is a practical and informative choice for whole‐brain ICC analysis that achieves a well‐balanced compromise when all potential fixed effects are accounted for. Third, approaches for clear, meaningful, and useful result reporting in ICC analysis are discussed. All models, ICC formulations, and related statistical testing methods have been implemented in an open source program 3dICC, which is publicly available as part of the AFNI suite. Even though our work here focuses on the whole‐brain level, the modeling strategy and recommendations can be equivalently applied to other situations such as voxel, region, and network levels.},
  doi        = {10.1002/hbm.23909},
  file       = {:Chen2017 - Intraclass Correlation_ Improved Modeling Approaches and Applications for Neuroimaging.pdf:PDF},
  groups     = {ICC},
  pmcid      = {PMC5807222},
  pmid       = {29218829},
  priority   = {prio1},
  shorttitle = {Intraclass correlation},
  url        = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5807222/},
  urldate    = {2023-10-27},
}

 
@Article{schemper1986,
  author   = {Schemper, M.},
  journal  = {Biometrical Journal},
  title    = {General derivation of intraclass correlation coefficients},
  year     = {1986},
  issn     = {1521-4036},
  number   = {4},
  pages    = {485--489},
  volume   = {28},
  abstract = {A general intraclass correlation coefficient is derived similarly to the general correlation coefficient given by {KENDALL} (1962). This coefficient {II} embraces as specific cases three intraclass correlations, related to Pearson's r, Kendall's tau and Spearman's rs, that were dealt with by {FISHER} (1921), {WHITFIELD} (1949), {SHIRAHATA} (1981) and {SCHEMPER} (1984). Formal relationships are presented and the qualification of the three coefficients for specific applications is discussed.},
  doi      = {10.1002/bimj.4710280418},
  file     = {:schemper1986 - General Derivation of Intraclass Correlation Coefficients.pdf:PDF},
  groups   = {ICC},
  keywords = {Analysis of pairs, Intraclass correlation, Generalized correlation},
  langid   = {english},
  rights   = {Copyright © 1986 {WILEY}-{VCH} Verlag {GmbH} \& Co. {KGaA}},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.4710280418},
  urldate  = {2023-10-31},
}

 
@Article{tisak1996,
  author     = {Tisak, John and Tisak, Marie S.},
  journal    = {Applied Psychological Measurement},
  title      = {Longitudinal {Models} of {Reliability} and {Validity}: {A} {Latent} {Curve} {Approach}},
  year       = {1996},
  issn       = {0146-6216},
  month      = sep,
  number     = {3},
  pages      = {275--288},
  volume     = {20},
  abstract   = {The concepts of reliability and validity and their associated coefficients typically have been restricted to a single measurement occasion. This paper describes dynamic generalizations of reliability and validity that will incorporate longitudinal or developmental models, using latent curve analysis. Initially a latent curve model is formulated to depict change. This longitudinal model is then incorporated into the classical definitions of reli ability and validity. This approach permits the separa tion of constancy or change from the indexes of reli ability and validity. Statistical estimation and hypoth esis testing be achieved using standard structural equations modeling computer programs. These longitu dinal models of reliability and validity are demon strated on sociological psychological data. Index terms: concurrent validity, dynamic models, dynamic true score, latent curve analysis, latent trajectory, predictive validity, reliability, validity.},
  doi        = {10.1177/014662169602000307},
  file       = {:tisak1996 - Longitudinal Models of Reliability and Validity_ a Latent Curve Approach.pdf:PDF},
  groups     = {Longitudinal data},
  language   = {en},
  publisher  = {SAGE Publications Inc},
  readstatus = {skimmed},
  shorttitle = {Longitudinal {Models} of {Reliability} and {Validity}},
  url        = {https://doi.org/10.1177/014662169602000307},
  urldate    = {2023-11-17},
}

 
@Article{brennan1977b,
  author       = {Brennan, Robert L. and Kane, Michael T.},
  journal      = {Psychometrika},
  title        = {Signal/noise ratios for domain-referenced tests},
  year         = {1977},
  issn         = {1860-0980},
  month        = dec,
  number       = {4},
  pages        = {609--625},
  volume       = {42},
  abstract     = {Using the assumption of randomly parallel tests and concepts from generalizability theory, three signal/noise ratios for domain-referenced tests are developed, discussed, and compared. The three ratios have the same noise but different signals depending upon the kind of decision to be made as a result of measurement. It is also shown that these ratios incorporate a definition of noise or error which is different from the classical definition of noise typically used to characterize norm-referenced tests.},
  doi          = {10.1007/BF02295983},
  file         = {:brennan1977b - Signal_noise Ratios for Domain Referenced Tests.pdf:PDF},
  groups       = {GT},
  keywords     = {domain-referenced testing, generalizability theory, signal/noise ratios, criterion-referenced testing, reliability},
  langid       = {english},
  ranking      = {rank4},
  readstatus   = {skimmed},
  shortjournal = {Psychometrika},
  url          = {https://doi.org/10.1007/BF02295983},
  urldate      = {2023-11-21},
}

 
@Article{hsiao2011,
  author       = {Hsiao, Chuhsing K. and Chen, Pei-Chun and Kao, Wen-Hsin},
  journal      = {Journal of Clinical Epidemiology},
  title        = {Bayesian random effects for interrater and test–retest reliability with nested clinical observations},
  year         = {2011},
  issn         = {0895-4356},
  month        = jul,
  number       = {7},
  pages        = {808--814},
  volume       = {64},
  abstract     = {Objective The assessment of inter- and intrarater reliability usually involves more than one level of nesting structures in the collected data, where repeated observations are made by multiple raters. Most approaches, however, are not designed to accommodate both inter- and intrarater reliability jointly, not to mention further difficulties arising when modeling with dichotomous responses. The multiple sources of dependence because of nesting structures and the existence of covariates can result in complexity in inference. Study Design and Setting We first establish the equivalence between correlation and kappa under common positive correlation models for multiple raters and then apply a Bayesian generalized linear mixed-effects model to interpret simultaneously both types of reproducibility through different annotations of similarity. In addition to marginal correlations, the correlated random effects among raters are adopted to infer similarity between raters, whereas the correlation for random time effects may contribute to test–retest reliability. Results This model accounts for individual covariates and random effects because of subjects, raters, and time, and it covers a wide variety of data structures and types. An application of endodontic radiographic examinations is illustrated. Conclusion This Bayesian hierarchical correlation model offers a wide applicability, flexibility, and feasibility in modeling inter- and intrarater reliability together.},
  doi          = {10.1016/j.jclinepi.2010.10.015},
  file         = {:hsiao2011 - Bayesian Random Effects for Interrater and Test–retest Reliability with Nested Clinical Observations.pdf:PDF;:hsiao2011 - S1.pdf:PDF},
  groups       = {Multilevel, Kappa},
  keywords     = {Agreement, Common correlation model, Kappa, {GLMM}, Reliability, Reproducibility},
  priority     = {prio2},
  readstatus   = {skimmed},
  shortjournal = {Journal of Clinical Epidemiology},
  url          = {https://www.sciencedirect.com/science/article/pii/S0895435610003823},
  urldate      = {2023-11-27},
}

 
@Article{vispoel2023,
  author       = {Vispoel, Walter P. and Lee, Hyeryung and Hong, Hyeri and Chen, Tingting},
  journal      = {Psychological Methods},
  title        = {Applying multivariate generalizability theory to psychological assessments},
  year         = {2023},
  issn         = {1082-989X},
  month        = sep,
  abstract     = {Multivariate generalizability theory ({GT}) represents a comprehensive framework for quantifying score consistency, separating multiple sources contributing to measurement error, correcting correlation coefficients for such error, assessing subscale viability, and determining the best ways to change measurement procedures at different levels of score aggregation. Despite such desirable attributes, multivariate {GT} has rarely been applied when measuring psychological constructs and far less often than univariate techniques that are subsumed within that framework. Our purpose in this tutorial is to describe multivariate {GT} in a simple way and illustrate how it expands and complements univariate procedures. We begin with a review of univariate {GT} designs and illustrate how such designs serve as subcomponents of corresponding multivariate designs. Our empirical examples focus primarily on subscale and composite scores for objectively scored measures, but guidelines are provided for applying the same techniques to subjectively scored performance and clinical assessments. We also compare multivariate {GT} indices of score consistency and measurement error to those obtained using alternative {GT}-based procedures and across different software packages for analyzing multivariate {GT} designs. Our online supplemental materials include instruction, code, and output for common multivariate {GT} designs analyzed using {mGENOVA} and the gtheory, {glmmTMB}, lavaan, and related packages in R. ({PsycInfo} Database Record (c) 2023 {APA}, all rights reserved)},
  doi          = {10.1037/met0000606.supp},
  file         = {:vispoel2023 - Applying Multivariate Generalizability Theory to Psychological Assessments.pdf:PDF},
  groups       = {GT},
  keywords     = {psychometrics, generalizability theory, multivariate analysis, Big Five Inventory, R programming, Error of Measurement, Five Factor Personality Model, Multivariate Analysis, Psychological Assessment, Psychometrics, Test Scores, Theories},
  publisher    = {American Psychological Association},
  shortjournal = {Psychological Methods},
  url          = {https://mu.idm.oclc.org/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=2024-05048-001&site=ehost-live&scope=site},
  urldate      = {2023-12-07},
}

 
@Article{wang2011,
  author   = {Wang, Luqiang and Keen, Kevin John and Holland, Burt},
  journal  = {Statistics in Medicine},
  title    = {Estimation of reliability in a three-factor model},
  year     = {2011},
  issn     = {1097-0258},
  number   = {11},
  pages    = {1254--1265},
  volume   = {30},
  abstract = {Reliability measures have been well studied over many years. Such measures have been thoroughly studied for two-factor models. Motivated by a medical research problem, point and confidence interval estimates of the intraclass correlation coefficient are extended to models containing three crossed random factors—subjects, raters, and occasions. The estimation is conducted using both analysis of variance and Monte Carlo Markov chain methods. Copyright © 2011 John Wiley \& Sons, Ltd.},
  doi      = {10.1002/sim.4182},
  file     = {:wang2011 - Estimation of Reliability in a Three Factor Model.pdf:PDF},
  groups   = {ICC},
  keywords = {reliability measures, intraclass correlation coefficient, three-way random effects model},
  langid   = {english},
  rights   = {Copyright © 2011 John Wiley \& Sons, Ltd.},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4182},
  urldate  = {2023-12-19},
}

@PhdThesis{schuurman2016,
  author = {Schuurman, No{\'{e}}mi K.},
  school = {Utrecht University},
  title  = {Multilevel autoregressive modeling in psychology: Snags and solutions},
  year   = {2016},
  note   = {(Unpublished doctoral dissertation)},
  file   = {:schuurman2016 - Multilevel Autoregressive Modeling in Psychology_ Snags and Solutions.pdf:PDF},
  groups = {Longitudinal data},
}

@Book{rykov2010,
  editor    = {Rykov, V. V. and Balakrishnan, N. and Nikulin, M. S.},
  publisher = {Birkhäuser Boston},
  title     = {Mathematical and statistical models and methods in reliability: Applications to medicine, finance, and quality control},
  year      = {2010},
  isbn      = {9780817649715},
  doi       = {10.1007/978-0-8176-4971-5},
  file      = {:C\:/Users/P70085765/OneDrive/DOCUME~1/BIBLIO~1/rykov2010 - Mathematical and Statistical Models and Methods in Reliability_ Applications to Medicine, Finance, and Quality Control.pdf:PDF},
  groups    = {Overview},
}

 
@Article{vanbelle2016a,
  author       = {Vanbelle, Sophie},
  journal      = {Psychometrika},
  title        = {A new interpretation of the weighted kappa coefficients},
  year         = {2016},
  issn         = {1860-0980},
  month        = jun,
  number       = {2},
  pages        = {399--410},
  volume       = {81},
  abstract     = {Reliability and agreement studies are of paramount importance. They do contribute to the quality of studies by providing information about the amount of error inherent to any diagnosis, score or measurement. Guidelines for reporting reliability and agreement studies were recently provided. While the use of the kappa-like family is advised for categorical and ordinal scales, no further guideline in the choice of a weighting scheme is given. In the present paper, a new simple and practical interpretation of the linear- and quadratic-weighted kappa coefficients is given. This will help researchers in motivating their choice of a weighting scheme.},
  doi          = {10.1007/s11336-014-9439-4},
  file         = {:vanbelle2016a - A New Interpretation of the Weighted Kappa Coefficients.pdf:PDF},
  groups       = {Kappa},
  keywords     = {agreement, reliability, ordinal scale, linear, quadratic},
  langid       = {english},
  shortjournal = {Psychometrika},
  url          = {https://doi.org/10.1007/s11336-014-9439-4},
  urldate      = {2024-01-29},
}

 
@Article{vanbelle2016,
  author       = {Vanbelle, Sophie and Lesaffre, Emmanuel},
  journal      = {Biostatistics},
  title        = {Modeling agreement on categorical scales in the presence of random scorers},
  year         = {2016},
  issn         = {1465-4644},
  month        = jan,
  number       = {1},
  pages        = {79--93},
  volume       = {17},
  abstract     = {Kappa coefficients are often used to assess agreement between two fixed scorers on categorical scales. Cohen's version is popular for nominal scales and the weighted version for ordinal scales. In the present paper, similar agreement coefficients are defined for random scorers. A partial-Bayesian methodology is then developed to directly relate these agreement coefficients to predictors through a multilevel model. Statistical properties of the proposed approach are studied using simulations. Finally, the approach is applied to gynecological and medical imaging data.},
  doi          = {10.1093/biostatistics/kxv036},
  file         = {:vanbelle2016 - Modeling Agreement on Categorical Scales in the Presence of Random Scorers.pdf:PDF},
  groups       = {Kappa},
  shortjournal = {Biostatistics},
  url          = {https://doi.org/10.1093/biostatistics/kxv036},
  urldate      = {2024-01-29},
}

@Book{hagiwara2021,
  author    = {Hagiwara, Junichiro},
  publisher = {Springer},
  title     = {Time series analysis for the state-space model with {R}/{Stan}},
  year      = {2021},
  isbn      = {9789811607110},
  doi       = {10.1007/978-981-16-0711-0},
  file      = {:hagiwara2021 - Time Series Analysis for the State Space Model with R_Stan.pdf:PDF},
  groups    = {SSM},
}
